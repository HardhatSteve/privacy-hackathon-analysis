# =============================================================================
# Spark Configuration
# =============================================================================
# Default configuration for Spark jobs in the auction pipeline.
# Adjust based on available resources and workload characteristics.
# =============================================================================

# Driver Configuration
spark.driver.memory                     1g
spark.driver.maxResultSize              512m

# Executor Configuration
spark.executor.memory                   2g
spark.executor.cores                    2
spark.executor.instances                2

# Shuffle Configuration
spark.sql.shuffle.partitions            200
spark.shuffle.compress                  true
spark.shuffle.spill.compress            true

# Streaming Configuration
spark.streaming.stopGracefullyOnShutdown    true
spark.streaming.backpressure.enabled        true
spark.streaming.kafka.maxRatePerPartition   1000

# SQL Configuration
spark.sql.adaptive.enabled              true
spark.sql.adaptive.coalescePartitions.enabled   true
spark.sql.adaptive.skewJoin.enabled     true

# Serialization
spark.serializer                        org.apache.spark.serializer.KryoSerializer
spark.kryoserializer.buffer.max         512m

# Compression
spark.io.compression.codec              snappy

# Dynamic Allocation (for production)
# spark.dynamicAllocation.enabled       true
# spark.dynamicAllocation.minExecutors  1
# spark.dynamicAllocation.maxExecutors  10

# Checkpointing
spark.checkpoint.compress               true

# Logging
spark.eventLog.enabled                  false
# spark.eventLog.dir                    /tmp/spark-events

# Memory Management
spark.memory.fraction                   0.6
spark.memory.storageFraction            0.5

# Network
spark.network.timeout                   300s
spark.rpc.askTimeout                    300s

# UI
spark.ui.showConsoleProgress            true
