
from __future__ import annotations

import base64
import base58
import hashlib
import json
import os
import pathlib
import secrets
import subprocess
import tempfile
import time
from datetime import datetime
from decimal import Decimal, ROUND_DOWN
from typing import Any, Dict, List, Optional

import nacl.bindings as nb
import requests
from fastapi import Body, Depends, FastAPI, File, Form, HTTPException, UploadFile, Request
from fastapi.responses import JSONResponse
from nacl import utils as nacl_utils
# Rate limiting imports - using custom middleware
import time
from collections import defaultdict
from datetime import datetime, timedelta
from nacl.secret import SecretBox

from services.crypto_core import stealth as st
from services.crypto_core.blind_api import (
    ensure_signer_keypair as _ensure_blind_keys,
)
from services.crypto_core.blind_api import load_pub as bs_load_pub, verify as bs_verify
from services.crypto_core.merkle import verify_merkle, MerkleTree as OldMerkleTree
from services.crypto_core.onchain_pool import (
    deposit_to_pool_onchain,
    prepare_deposit_params,
    withdraw_from_pool_onchain,
    MerkleTree as PoolMerkleTree,
    h1,
    h2,
    get_pubkey_from_keypair
)
from services.crypto_core.wrapper_stealth import (
    initialize_wrapper_stealth_state,
    load_wrapper_stealth_state,
    DEFAULT_STATE_PATH as WRAPPER_STEALTH_STATE_PATH
)
from pathlib import Path

# Database imports
from sqlalchemy import select, and_, or_
from sqlalchemy.ext.asyncio import AsyncSession

from . import cli_adapter as ca
from . import eventlog as ev
from .schemas_api import (
    BuyReq,
    BuyRes,
    DepositReq,
    DepositRes,
    EncryptedBlob,
    EscrowActionReq,
    EscrowActionRes,
    EscrowGetRes,
    EscrowListRes,
    EscrowMerkleStatus,
    EscrowOpenReq,
    EscrowOpenRes,
    EscrowRecord,
    Listing,
    ListingCreateRes,
    ListingDeleteRes,
    ListingUpdateRes,
    ListingsPayload,
    ListNotesRes,
    MarkStealthUsedReq,
    MarkStealthUsedRes,
    MessageRow,
    MessageSendReq,
    MessageSendRes,
    MessagesListRes,
    MessagesMerkleStatus,
    MerkleStatus,
    MetricRow,
    NoteInfo,
    ProfileBlob,
    ProfileRevealReq,
    ProfileRevealRes,
    ProfileResolveRes,
    ProfileRotateReq,
    StealthItem,
    StealthList,
    SweepReq,
    SweepRes,
    WithdrawReq,
    WithdrawRes,
)

try:
    _ensure_blind_keys()
except Exception:
    pass

try:
    from . import schemas_api as _schemas

    _schemas.ProfileResolveRes.update_forward_refs(**_schemas.__dict__)
    _schemas.ProfileRevealRes.update_forward_refs(**_schemas.__dict__)
except Exception:
    pass

app = FastAPI(title="Incognito Protocol API", version="0.1.0")

# ============================================================================
# CONSTANTS
# ============================================================================
# CRITICAL: Merkle tree depth must match on-chain contract depth
MERKLE_TREE_DEPTH = 10

# ============================================================================
# LOGGING & ERROR HANDLING
# ============================================================================
from services.api.logging_config import setup_logging, get_logger, api_logger
from services.api.logging_middleware import RequestLoggingMiddleware, SlowRequestLoggingMiddleware
from services.api.error_handlers import register_exception_handlers
from services.api.exceptions import (
    IncognitoException,
    ValidationException,
    KeyfileNotFoundException,
    ResourceNotFoundException,
    TransactionFailedException,
    InsufficientBalanceException,
)

# Setup logging (will be configured fully at startup)
# Using human-readable format for development, JSON for production
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO")
LOG_FILE = Path(os.getenv("LOG_FILE", "logs/api.log")) if os.getenv("LOG_FILE") else None
JSON_LOGS = os.getenv("JSON_LOGS", "false").lower() == "true"

setup_logging(log_level=LOG_LEVEL, log_file=LOG_FILE, json_format=JSON_LOGS)

# Register exception handlers
register_exception_handlers(app)

# Add logging middleware
app.add_middleware(RequestLoggingMiddleware)
app.add_middleware(SlowRequestLoggingMiddleware, threshold_ms=2000.0)  # Log requests > 2s

api_logger.info("Logging and error handling configured")

# ============================================================================
# SECURITY MIDDLEWARE
# ============================================================================
from services.api.security_middleware import (
    SecurityHeadersMiddleware,
    RequestValidationMiddleware,
    configure_cors
)
from services.api.validators import validate_keyfile_path, ValidationError

# Add security middleware
app.add_middleware(SecurityHeadersMiddleware)
app.add_middleware(RequestValidationMiddleware)

# Configure CORS
configure_cors(app)

api_logger.info("Security middleware configured")

# ============================================================================
# RATE LIMITING - Custom Middleware Approach
# ============================================================================
# Simple in-memory rate limiter (for production, use Redis)
rate_limit_storage = defaultdict(list)

def check_rate_limit(client_ip: str, endpoint: str, max_requests: int, window_seconds: int = 60) -> tuple[bool, int]:
    """
    Check if request exceeds rate limit.

    Returns: (is_allowed, retry_after_seconds)
    """
    key = f"{client_ip}:{endpoint}"
    now = time.time()

    # Clean old requests outside the window
    rate_limit_storage[key] = [req_time for req_time in rate_limit_storage[key]
                               if now - req_time < window_seconds]

    # Check if limit exceeded
    if len(rate_limit_storage[key]) >= max_requests:
        oldest_request = min(rate_limit_storage[key])
        retry_after = int(window_seconds - (now - oldest_request)) + 1
        return False, retry_after

    # Add current request
    rate_limit_storage[key].append(now)
    return True, 0

@app.middleware("http")
async def rate_limit_middleware(request: Request, call_next):
    """Global rate limiting middleware"""
    client_ip = request.client.host if request.client else "unknown"
    endpoint = request.url.path

    # Define rate limits per endpoint
    endpoint_limits = {
        "/deposit": (10, 60),  # 10 requests per minute
        "/withdraw": (10, 60),
        "/marketplace/buy": (20, 60),
        "/notes/store": (50, 60),
        "/notes/": (100, 60),  # Prefix match for /notes/{owner_pub}
        "/listings": (30, 3600) if request.method == "POST" else (200, 60),  # 30/hour for POST, 200/min for GET
        "/messages/send": (100, 60),
        "/escrow": (30, 60),
    }

    # Find matching rate limit
    max_requests, window = 200, 60  # Default: 200/minute
    for path_prefix, (limit, win) in endpoint_limits.items():
        if endpoint.startswith(path_prefix):
            max_requests, window = limit, win
            break

    # Check rate limit
    is_allowed, retry_after = check_rate_limit(client_ip, endpoint, max_requests, window)

    if not is_allowed:
        return JSONResponse(
            status_code=429,
            content={
                "error": "rate_limit_exceeded",
                "detail": f"Too many requests. Please slow down and try again in {retry_after} seconds.",
                "retry_after": retry_after
            },
            headers={"Retry-After": str(retry_after)}
        )

    # Add rate limit headers to response
    response = await call_next(request)
    remaining = max_requests - len(rate_limit_storage[f"{client_ip}:{endpoint}"])
    response.headers["X-RateLimit-Limit"] = str(max_requests)
    response.headers["X-RateLimit-Remaining"] = str(max(0, remaining))
    response.headers["X-RateLimit-Reset"] = str(int(time.time() + window))

    return response

api_logger.info("Rate limiting enabled (middleware-based)")

# Database setup - import here to avoid circular imports
try:
    from services.database.config import get_async_session, test_connection_async
    from services.database.models import (
        EncryptedNote,
        Listing as DBListing,
        Escrow as DBEscrow,
        Message as DBMessage,
        EscrowState,
        AuditLog,
    )
    from services.crypto_core.field_encryption import hash_pubkey

    DATABASE_ENABLED = True
    api_logger.info("Database support enabled")
except Exception as e:
    DATABASE_ENABLED = False
    api_logger.warning(f"Database support disabled: {e}. API will use JSON file storage")

# Dependency injection
async def get_db() -> AsyncSession:
    """Get database session (FastAPI dependency)"""
    if not DATABASE_ENABLED:
        raise HTTPException(status_code=503, detail="Database not configured")
    async with get_async_session() as session:
        yield session

@app.on_event("startup")
async def startup_event():
    """Initialize wrapper stealth state, escrow platform, and transaction manager on startup"""
    global DATABASE_ENABLED

    api_logger.info("Starting Incognito Protocol API...")

    # Initialize Sentry for error tracking
    try:
        from services.api.sentry_integration import init_sentry

        sentry_enabled = init_sentry(
            environment=os.getenv("SENTRY_ENVIRONMENT", "development"),
            traces_sample_rate=float(os.getenv("SENTRY_TRACES_SAMPLE_RATE", "0.1")),
            profiles_sample_rate=float(os.getenv("SENTRY_PROFILES_SAMPLE_RATE", "0.1"))
        )

        if sentry_enabled:
            api_logger.info("Sentry error tracking enabled")
        else:
            api_logger.info("Sentry error tracking disabled (no DSN configured)")
    except Exception as e:
        api_logger.warning(f"Sentry initialization failed: {e}")

    # Initialize Transaction Manager for robust transaction handling
    try:
        from services.api.transaction_manager import init_transaction_manager
        import os

        # Get RPC endpoints from environment (with localnet as fallback)
        rpc_url = os.getenv("SOLANA_RPC_URL", "http://127.0.0.1:8899")
        backup_rpc = os.getenv("SOLANA_BACKUP_RPC_URL")  # Optional backup

        rpc_endpoints = [rpc_url]
        if backup_rpc:
            rpc_endpoints.append(backup_rpc)

        init_transaction_manager(rpc_endpoints)
        api_logger.info(f"Transaction Manager initialized with {len(rpc_endpoints)} RPC endpoint(s)")
    except Exception as e:
        api_logger.warning(f"Transaction Manager initialization failed: {e}. Transactions will use basic send without retry logic")

    # Test database connection
    if DATABASE_ENABLED:
        try:
            await test_connection_async()
            api_logger.info("Database connection successful")
        except Exception as e:
            api_logger.error(f"Database connection failed: {e}. Falling back to JSON file storage")
            DATABASE_ENABLED = False

    try:
        load_wrapper_stealth_state(WRAPPER_STEALTH_STATE_PATH)
        api_logger.info("Wrapper stealth state loaded")
    except FileNotFoundError:
        wrapper_keyfile = ca.WRAPPER_KEYPAIR
        if os.path.exists(wrapper_keyfile):
            wrapper_pubkey = ca.get_pubkey_from_keypair(wrapper_keyfile)
            initialize_wrapper_stealth_state(
                wrapper_master_pubkey=wrapper_pubkey,
                state_path=WRAPPER_STEALTH_STATE_PATH
            )
            api_logger.info(f"Initialized wrapper stealth state at {WRAPPER_STEALTH_STATE_PATH}")
        else:
            api_logger.warning(f"Wrapper keyfile not found at {wrapper_keyfile}")

    try:
        api_logger.info("Initializing escrow platform...")
        ca._ensure_escrow_platform_initialized()
        api_logger.info("Escrow platform ready")
    except Exception as e:
        api_logger.warning(f"Failed to initialize escrow platform: {e}. Escrow features may not work until platform is initialized")

    api_logger.info("üöÄ Incognito Protocol API startup complete")

@app.on_event("shutdown")
async def shutdown_event():
    """Cleanup on shutdown"""
    api_logger.info("Shutting down Incognito Protocol API...")

    try:
        from services.api.transaction_manager import get_transaction_manager
        tx_manager = get_transaction_manager()
        await tx_manager.close()

        # Log transaction stats
        stats = tx_manager.stats
        api_logger.info(
            f"Transaction Manager stats: {stats['successful_sends']} successful, "
            f"{stats['failed_sends']} failed, {stats['total_attempts']} total attempts"
        )
        api_logger.info("Transaction Manager shut down gracefully")
    except Exception as e:
        api_logger.warning(f"Transaction Manager shutdown: {e}")

    # Flush Sentry events
    try:
        from services.api.sentry_integration import flush_sentry
        flush_sentry(timeout=2)
        api_logger.info("Sentry events flushed")
    except Exception as e:
        api_logger.warning(f"Sentry flush: {e}")

    api_logger.info("üëã Incognito Protocol API shutdown complete")


REPO_ROOT = str(pathlib.Path(__file__).resolve().parents[2])
DATA_DIR = os.getenv("DATA_DIR", os.path.join(REPO_ROOT, "data"))
os.makedirs(DATA_DIR, exist_ok=True)

CLUSTER_FP_PATH = os.path.join(DATA_DIR, "cluster_fingerprint.json")
SOLANA_RPC_URL = os.getenv("SOLANA_RPC_URL", "http://127.0.0.1:8899")

CSOL_LEDGER_PATH = os.path.join(DATA_DIR, "csol_ledger.json")
CSOL_SUPPLY_FILE = os.path.join(DATA_DIR, "csol_supply.json")
SHIPPING_EVENTS_PATH = os.path.join(DATA_DIR, "shipping_events.jsonl")
SHIPPING_MERKLE_PATH = os.path.join(DATA_DIR, "shipping_merkle.json")

PROFILES_EVENTS = os.path.join(DATA_DIR, "profiles.jsonl")
PROFILES_MERKLE = os.path.join(DATA_DIR, "profiles_merkle.json")
USED_STEALTH_PATH = os.path.join(DATA_DIR, "used_stealth.jsonl")

MESSAGES_EVENTS_PATH = os.path.join(DATA_DIR, "messages.jsonl")
MESSAGES_MERKLE_PATH = os.path.join(DATA_DIR, "messages_merkle.json")

USER_NOTES_PATH = os.path.join(DATA_DIR, "user_notes.json")

NOTES_DIR = os.path.join(REPO_ROOT, "notes")

IPFS_GATEWAY = os.getenv("IPFS_GATEWAY", "http://127.0.0.1:8080/ipfs/")

TREASURY_KEYFILE = os.getenv(
    "TREASURY_KEYFILE",
    "/Users/alex/Desktop/incognito-protocol-1/keys/pool.json",
)

for p, default in [
    (CSOL_LEDGER_PATH, "{}"),
    (CSOL_SUPPLY_FILE, '{"total":"0"}'),
    (SHIPPING_EVENTS_PATH, ""),
    (SHIPPING_MERKLE_PATH, json.dumps({"leaves": [], "root": None, "version": 1})),
    (PROFILES_EVENTS, ""),
    (PROFILES_MERKLE, json.dumps({"leaves": [], "root": None, "version": 1})),
    (USED_STEALTH_PATH, ""),
    (MESSAGES_EVENTS_PATH, ""),
    (MESSAGES_MERKLE_PATH, json.dumps({"leaves": [], "root": None, "version": 1})),
    (USER_NOTES_PATH, "{}"),
]:
    if not os.path.exists(p):
        try:
            pathlib.Path(p).write_text(default if isinstance(default, str) else json.dumps(default))
        except Exception:
            pass

ESCROW_STATE_PATH = os.path.join(DATA_DIR, "escrow_state.json")
ESCROW_MERKLE_PATH = os.path.join(DATA_DIR, "escrow_merkle_state.json")

for p, default in [
    (ESCROW_STATE_PATH, json.dumps({"escrows": [], "nullifiers": []})),
    (ESCROW_MERKLE_PATH, json.dumps({"leaves": [], "root": ""})),
]:
    if not os.path.exists(p):
        try:
            pathlib.Path(p).write_text(default)
        except Exception:
            pass


AUTO_WIPE = os.getenv("AUTO_WIPE_ON_CLUSTER_CHANGE", "1") == "1"

def _rpc(method: str, params=None) -> dict:
    try:
        r = requests.post(
            SOLANA_RPC_URL,
            json={"jsonrpc": "2.0", "id": 1, "method": method, "params": params or []},
            timeout=5,
        )
        r.raise_for_status()
        return r.json()
    except Exception as e:
        return {"error": str(e)}

def _get_genesis_hash() -> str | None:
    j = _rpc("getGenesisHash")
    return j.get("result") if isinstance(j, dict) else None

def _get_identity_pub() -> str | None:
    j = _rpc("getIdentity")
    try:
        return (j or {}).get("result", {}).get("identity")
    except Exception:
        return None

def _load_fp() -> dict:
    try:
        return json.loads(pathlib.Path(CLUSTER_FP_PATH).read_text())
    except Exception:
        return {}

def _save_fp(fp: dict) -> None:
    try:
        pathlib.Path(CLUSTER_FP_PATH).write_text(json.dumps(fp))
    except Exception:
        pass

def _unlink(path: str | None):
    if not path:
        return
    try:
        os.remove(path)
    except Exception:
        pass

def _autowipe_on_cluster_change():
    if not AUTO_WIPE:
        return
    cur_genesis = _get_genesis_hash()
    cur_ident = _get_identity_pub()
    if not cur_genesis:
        return
    cur_fp = {"rpc": SOLANA_RPC_URL, "genesis": cur_genesis, "identity": cur_ident}
    prev = _load_fp()
    if prev == cur_fp:
        return
    try:
        try:
            ca.listings_reset_all()
        except Exception:
            pass
        _unlink(CSOL_LEDGER_PATH)
        _unlink(CSOL_SUPPLY_FILE)
        _unlink(SHIPPING_EVENTS_PATH)
        _unlink(SHIPPING_MERKLE_PATH)
        _unlink(PROFILES_EVENTS)
        _unlink(PROFILES_MERKLE)
        _unlink(USED_STEALTH_PATH)
        lst_path = os.getenv("LISTINGS_STATE_FILE")
        _unlink(lst_path)
        pathlib.Path(CSOL_LEDGER_PATH).write_text(json.dumps({}))
        pathlib.Path(CSOL_SUPPLY_FILE).write_text(json.dumps({"total": "0"}))
        pathlib.Path(SHIPPING_EVENTS_PATH).write_text("")
        pathlib.Path(SHIPPING_MERKLE_PATH).write_text(
            json.dumps({"leaves": [], "root": None, "version": 1})
        )
    finally:
        _save_fp(cur_fp)

def _account_exists(pub: str) -> bool:
    j = _rpc("getAccountInfo", [pub, {"encoding": "base64"}])
    try:
        return bool(((j or {}).get("result") or {}).get("value"))
    except Exception:
        return False

def _reconcile_listings():
    try:
        items = ca.listings_active()
    except Exception:
        return
    for it in items or []:
        lid = str(it.get("id") or it.get("listing_id") or "")
        spk = str(it.get("seller_pub") or "")
        if not lid or not spk:
            continue
        if not _account_exists(spk):
            try:
                ca.listing_delete(owner_pubkey=spk, listing_id_hex=lid)
            except Exception:
                pass
            continue
        try:
            rc, out, err = ca._run_rc(["spl-token", "address", ca.MINT, "--owner", spk, "--verbose"])
            ok = (rc == 0) and ("associated token address:" in (out or "").lower())
            if not ok:
                try:
                    ca.listing_delete(owner_pubkey=spk, listing_id_hex=lid)
                except Exception:
                    pass
        except Exception:
            try:
                ca.listing_delete(owner_pubkey=spk, listing_id_hex=lid)
            except Exception:
                pass

_autowipe_on_cluster_change()
_reconcile_listings()

MESSAGES_PID = os.getenv("MESSAGES_PROGRAM_ID", "Msg11111111111111111111111111111111111111111")
INCOGNITO_DIR = pathlib.Path(REPO_ROOT) / "contracts" / "incognito"


def _shipping__ensure_files():
    if not os.path.exists(SHIPPING_EVENTS_PATH):
        try:
            pathlib.Path(SHIPPING_EVENTS_PATH).write_text("")
        except Exception:
            pass
    if not os.path.exists(SHIPPING_MERKLE_PATH):
        try:
            pathlib.Path(SHIPPING_MERKLE_PATH).write_text(
                json.dumps({"leaves": [], "root": None, "version": 1})
            )
        except Exception:
            pass

def _shipping_events_append(row: dict) -> None:
    try:
        with open(SHIPPING_EVENTS_PATH, "a", encoding="utf-8") as f:
            f.write(json.dumps(row, separators=(",", ":")) + "\n")
    except Exception:
        pass

def _shipping_events_read_all() -> list[dict]:
    out = []
    try:
        with open(SHIPPING_EVENTS_PATH, "r", encoding="utf-8") as f:
            for line in f:
                if not line.strip():
                    continue
                try:
                    out.append(json.loads(line))
                except Exception:
                    continue
    except FileNotFoundError:
        pass
    return out

def _shipping_load_state() -> Dict[str, Any]:
    _shipping__ensure_files()
    try:
        return json.loads(pathlib.Path(SHIPPING_MERKLE_PATH).read_text())
    except Exception:
        return {"leaves": [], "root": None, "version": 1}

def _shipping_save_state(st: Dict[str, Any]) -> None:
    try:
        pathlib.Path(SHIPPING_MERKLE_PATH).write_text(json.dumps(st))
    except Exception:
        pass

def _shipping_canon_bytes(blob: Dict[str, Any]) -> bytes:
    return json.dumps(blob, sort_keys=True, separators=(",", ":")).encode("utf-8")

def _shipping_leaf_hex(blob: Dict[str, Any]) -> str:
    h = hashlib.sha256()
    h.update(b"ship|")
    h.update(_shipping_canon_bytes(blob))
    return h.hexdigest()

def _shipping_build_tree(leaves_hex: List[str]) -> MerkleTree:
    mt = OldMerkleTree(leaves_hex if isinstance(leaves_hex, list) else [])
    if not getattr(mt, "layers", None) and getattr(mt, "leaf_bytes", None):
        mt.build_tree()
    return mt

def _shipping_append_event(
    order_id: str,
    listing_id: str,
    buyer_pub: str,
    seller_pub: str,
    encrypted_blob: Dict[str, Any],
) -> Dict[str, Any]:
    _shipping__ensure_files()
    leaf_hex = _shipping_leaf_hex(encrypted_blob)
    row = {
        "type": "shipping_blob",
        "ts": datetime.utcnow().isoformat() + "Z",
        "order_id": order_id,
        "listing_id": listing_id,
        "buyer_pub": buyer_pub,
        "seller_pub": seller_pub,
        "leaf": leaf_hex,
        "blob": encrypted_blob,
    }
    try:
        with open(SHIPPING_EVENTS_PATH, "a", encoding="utf-8") as f:
            f.write(json.dumps(row, separators=(",", ":")) + "\n")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to write shipping event: {e}")

    st = _shipping_load_state()
    st["leaves"].append(leaf_hex)
    mt = _shipping_build_tree(st["leaves"])
    root_hex = mt.root().hex()
    st["root"] = root_hex
    _shipping_save_state(st)
    idx = len(st["leaves"]) - 1
    proof = mt.get_proof(idx)
    return {"leaf": leaf_hex, "root": root_hex, "index": idx, "proof": proof, "order_id": order_id}

def _shipping_find_by_order(order_id: str) -> Optional[Dict[str, Any]]:
    _shipping__ensure_files()
    target_row = None
    try:
        with open(SHIPPING_EVENTS_PATH, "r", encoding="utf-8") as f:
            for line in f:
                if not line.strip():
                    continue
                row = json.loads(line)
                if row.get("type") == "shipping_blob" and row.get("order_id") == order_id:
                    target_row = row
    except FileNotFoundError:
        pass
    if not target_row:
        return None
    st = _shipping_load_state()
    leaves = st.get("leaves", [])
    if not isinstance(leaves, list):
        leaves = []
    try:
        idx = leaves.index(target_row["leaf"])
    except ValueError:
        idx = None
    mt = _shipping_build_tree(leaves)
    root_hex = mt.root().hex()
    proof = mt.get_proof(idx) if idx is not None else []
    return {
        "order_id": order_id,
        "listing_id": target_row.get("listing_id"),
        "buyer_pub": target_row.get("buyer_pub"),
        "seller_pub": target_row.get("seller_pub"),
        "encrypted_shipping": target_row.get("blob"),
        "leaf": target_row.get("leaf"),
        "root": root_hex,
        "index": idx if idx is not None else -1,
        "proof": proof,
    }


def _load_user_notes() -> Dict[str, List[Dict[str, Any]]]:
    """Load notes database (owner_pub -> list of notes)"""
    try:
        return json.loads(pathlib.Path(USER_NOTES_PATH).read_text())
    except Exception:
        return {}

def _save_user_notes(notes_db: Dict[str, List[Dict[str, Any]]]) -> None:
    """Save notes database"""
    try:
        pathlib.Path(USER_NOTES_PATH).write_text(json.dumps(notes_db, indent=2))
    except Exception:
        pass

async def _save_note_for_user_db(
    owner_pub: str,
    encrypted_blob: dict,
    commitment: str,
    tx_signature: str,
    spent: bool = False
) -> None:
    """
    Save a note to database with CLIENT-SIDE encryption.

    The encrypted_blob is already encrypted by the client using their Solana keypair.
    The API server is BLIND - it cannot decrypt this data.

    Args:
        owner_pub: User's public key (for query indexing)
        encrypted_blob: Client-encrypted note data {"ciphertext": "...", "nonce": "..."}
        commitment: Public commitment (on-chain)
        tx_signature: Transaction signature
        spent: Whether note is spent
    """
    if not DATABASE_ENABLED:
        raise RuntimeError(
            "DATABASE REQUIRED: Note storage requires PostgreSQL database. "
            "JSON fallback is NOT supported. Please configure database connection."
        )

    try:
        from sqlalchemy.exc import IntegrityError

        async with get_async_session() as session:
            # Check if note already exists (prevent duplicate insertions)
            from sqlalchemy import select
            existing_note = await session.execute(
                select(EncryptedNote).where(EncryptedNote.commitment == commitment)
            )
            if existing_note.scalar_one_or_none():
                print(f"‚ÑπÔ∏è  Note with commitment {commitment[:8]}... already exists in database, skipping")
                return

            # Create note with client-encrypted blob (API cannot decrypt!)
            note = EncryptedNote(
                owner_pubkey=owner_pub,
                commitment=commitment,
                encrypted_blob=encrypted_blob  # Store as-is, can't read it!
            )
            note.spent = spent

            session.add(note)
            await session.commit()

            # Audit log (no amount - we can't see it!)
            audit = AuditLog(
                event_type="note_created",
                event_data={
                    "commitment": commitment,
                    "tx_signature": tx_signature,
                    # No amount_sol - we can't decrypt it!
                },
                actor_pubkey=owner_pub,
            )
            session.add(audit)
            await session.commit()

            print(f"‚úÖ Note {commitment[:8]}... saved to database")
    except IntegrityError as e:
        # Note already exists - this is fine, just log and continue
        if "duplicate key" in str(e).lower() and "commitment" in str(e).lower():
            print(f"‚ÑπÔ∏è  Note {commitment[:8]}... already exists (duplicate commitment), skipping")
        else:
            print(f"‚ùå Database integrity error: {e}")
            raise
    except Exception as e:
        print(f"‚ùå Database save failed: {e}")
        raise

def _save_note_for_user_json(
    owner_pub: str,
    secret: str,
    nullifier: str,
    commitment: str,
    leaf_index: int,
    amount_sol: float,
    tx_signature: str,
    spent: bool = False
) -> None:
    """Save a note for a user (JSON fallback)"""
    notes_db = _load_user_notes()
    if owner_pub not in notes_db:
        notes_db[owner_pub] = []

    note = {
        "secret": secret,
        "nullifier": nullifier,
        "commitment": commitment,
        "leaf_index": leaf_index,
        "amount_sol": str(amount_sol),
        "tx_signature": tx_signature,
        "spent": spent
    }

    notes_db[owner_pub].append(note)
    _save_user_notes(notes_db)

def _save_note_for_user(
    owner_pub: str,
    secret: str,
    nullifier: str,
    commitment: str,
    leaf_index: int,
    amount_sol: float,
    tx_signature: str,
    spent: bool = False
) -> None:
    """Save a note for a user (synchronous wrapper for backward compatibility)"""
    _save_note_for_user_json(owner_pub, secret, nullifier, commitment, leaf_index, amount_sol, tx_signature, spent)

async def _mark_note_spent_db(commitment: str, nullifier: str, owner_pub: str = None) -> None:
    """
    Mark a note as spent by commitment (CLIENT-SIDE ENCRYPTION compatible).

    With client-side encryption, the API cannot decrypt notes to match nullifiers.
    Instead, the client sends the commitment (which is public) to identify the note.

    Args:
        commitment: Note commitment to mark as spent
        nullifier: Nullifier for audit/registry (not used for lookup)
        owner_pub: Owner pubkey for audit logging (optional)
    """
    if not DATABASE_ENABLED:
        raise RuntimeError(
            "DATABASE REQUIRED: Note management requires PostgreSQL database. "
            "JSON fallback is NOT supported. Please configure database connection."
        )

    try:
        import hashlib
        async with get_async_session() as session:
            # Find note by commitment (public field)
            query = select(EncryptedNote).where(
                and_(
                    EncryptedNote.commitment == commitment,
                    EncryptedNote.spent == False
                )
            )
            result = await session.execute(query)
            note = result.scalar_one_or_none()

            if not note:
                print(f"‚ö†Ô∏è  Note with commitment {commitment[:8]}... not found or already spent")
                if owner_pub:
                    _mark_note_spent_json(owner_pub, nullifier)
                return

            # Mark as spent
            note.mark_spent()

            # Register nullifier
            nullifier_hash = hashlib.sha256(nullifier.encode('utf-8')).hexdigest()
            from services.database.models import NullifierRegistry
            null_reg = NullifierRegistry(
                nullifier=nullifier,
                commitment=commitment,
                tx_signature=None
            )
            session.add(null_reg)

            await session.commit()

            # Audit log
            if owner_pub:
                audit = AuditLog(
                    event_type="note_spent",
                    event_data={
                        "commitment": commitment,
                        "nullifier_hash": nullifier_hash,
                    },
                    actor_pubkey=owner_pub,
                )
                session.add(audit)
                await session.commit()

            print(f"‚úÖ Note {commitment[:8]}... marked as spent")
    except Exception as e:
        print(f"‚ùå Database mark spent failed: {e}")
        raise

def _mark_note_spent_json(owner_pub: str, nullifier: str) -> None:
    """Mark a note as spent by nullifier (JSON fallback)"""
    notes_db = _load_user_notes()
    if owner_pub in notes_db:
        for note in notes_db[owner_pub]:
            if note.get("nullifier") == nullifier:
                note["spent"] = True
        _save_user_notes(notes_db)

def _mark_note_spent(owner_pub: str, nullifier: str) -> None:
    """Mark a note as spent by nullifier (synchronous wrapper for backward compatibility)"""
    _mark_note_spent_json(owner_pub, nullifier)

async def _get_user_notes_db(owner_pub: str, include_spent: bool = False) -> List[Dict[str, Any]]:
    """
    Get all notes for a user from database (CLIENT-SIDE ENCRYPTED).

    Returns encrypted blobs - the API server CANNOT decrypt them.
    Client must decrypt locally with their private key.

    Args:
        owner_pub: User's public key
        include_spent: Whether to include spent notes

    Returns:
        List of notes with encrypted blobs (NOT decrypted!)
    """
    if not DATABASE_ENABLED:
        raise RuntimeError(
            "DATABASE REQUIRED: Note retrieval requires PostgreSQL database. "
            "JSON fallback is NOT supported. Please configure database connection."
        )

    try:
        async with get_async_session() as session:
            pubkey_hash = hash_pubkey(owner_pub)

            # Build query
            query = select(EncryptedNote).where(EncryptedNote.owner_pubkey_hash == pubkey_hash)
            if not include_spent:
                query = query.where(EncryptedNote.spent == False)

            # Execute
            result = await session.execute(query)
            db_notes = result.scalars().all()

            # Return encrypted blobs (DON'T decrypt - we can't!)
            notes = []
            for db_note in db_notes:
                notes.append({
                    "commitment": db_note.commitment,
                    "encrypted_blob": db_note.encrypted_blob,  # Still encrypted!
                    "spent": db_note.spent,
                    "created_at": db_note.created_at.isoformat() if db_note.created_at else None
                })

            return notes
    except Exception as e:
        print(f"‚ùå Database query failed: {e}")
        raise

def _get_user_notes_json(owner_pub: str, include_spent: bool = False) -> List[Dict[str, Any]]:
    """Get all notes for a user from JSON"""
    notes_db = _load_user_notes()
    notes = notes_db.get(owner_pub, [])
    if not include_spent:
        notes = [n for n in notes if not n.get("spent", False)]
    return notes

def _get_user_notes(owner_pub: str, include_spent: bool = False) -> List[Dict[str, Any]]:
    """Get all notes for a user (synchronous wrapper for backward compatibility)"""
    return _get_user_notes_json(owner_pub, include_spent)

def _delete_note_file(commitment: str) -> None:
    """
    Delete a note file from the /notes directory based on commitment.
    Files are named like: note_XXXXXXXX_timestamp.json where XXXXXXXX is first 8 chars of commitment hex.
    """
    try:
        import glob
        commitment_prefix = commitment[:8]
        pattern = os.path.join(NOTES_DIR, f"note_{commitment_prefix}_*.json")
        matching_files = glob.glob(pattern)

        for file_path in matching_files:
            try:
                with open(file_path, 'r') as f:
                    note_data = json.load(f)
                if note_data.get("credentials", {}).get("commitment") == commitment:
                    os.remove(file_path)
                    print(f"   Deleted spent note file: {os.path.basename(file_path)}")
                    return
            except Exception:
                continue
    except Exception as e:
        print(f"   Warning: Could not delete note file for {commitment[:8]}: {e}")

def _create_change_note_file(
    secret: str,
    nullifier: str,
    commitment: str,
    leaf_index: int,
    amount_sol: float,
    tx_signature: str
) -> None:
    """
    Create a change note file in the /notes directory.
    Files are named like: change_XXXXXXXX_timestamp.json
    """
    try:
        os.makedirs(NOTES_DIR, exist_ok=True)

        commitment_prefix = commitment[:8]
        timestamp = int(datetime.now().timestamp())
        filename = f"change_{commitment_prefix}_{timestamp}.json"
        filepath = os.path.join(NOTES_DIR, filename)

        note_data = {
            "version": "1.0",
            "network": "localnet",
            "deposit_date": datetime.now().isoformat(),
            "amount_deposited_sol": amount_sol,
            "amount_withdrawable_sol": amount_sol,
            "wrapper_fee_sol": 0.0,
            "credentials": {
                "secret": secret,
                "nullifier": nullifier,
                "commitment": commitment,
                "leaf_index": leaf_index
            },
            "transaction": {
                "tx_signature": tx_signature,
                "note_type": "change"
            }
        }

        with open(filepath, 'w') as f:
            json.dump(note_data, f, indent=2)

        print(f"   Created change note file: {filename}")
    except Exception as e:
        print(f"   Warning: Could not create change note file: {e}")

CSOL_DEC = Decimal("0.000000001")
CHUNK = Decimal("100")

def _fmt(x: Decimal | float | str) -> str:
    return str(Decimal(str(x)).quantize(CSOL_DEC))

def _q(x: Decimal | str | float) -> Decimal:
    return Decimal(str(x)).quantize(CSOL_DEC)

def _ledger_load() -> dict:
    try:
        return json.loads(pathlib.Path(CSOL_LEDGER_PATH).read_text())
    except Exception:
        return {}

def _ledger_save(d: dict) -> None:
    try:
        pathlib.Path(CSOL_LEDGER_PATH).write_text(json.dumps(d))
    except Exception:
        pass

def _csol_get(pub: str) -> Decimal:
    try:
        return _q(_ledger_load().get(pub, "0"))
    except Exception:
        return Decimal("0")

def _csol_add(pub: str, amt: Decimal | str | float) -> None:
    d = _ledger_load()
    cur = _q(d.get(pub, "0"))
    newv = _q(cur + _q(amt))
    d[pub] = str(newv)
    _ledger_save(d)

def _csol_sub(pub: str, amt: Decimal | str | float) -> None:
    d = _ledger_load()
    cur = _q(d.get(pub, "0"))
    newv = _q(cur - _q(amt))
    if newv <= 0:
        d.pop(pub, None)
    else:
        d[pub] = str(newv)
    _ledger_save(d)

def _supply_load() -> Decimal:
    try:
        d = json.loads(pathlib.Path(CSOL_SUPPLY_FILE).read_text())
        return _q(d.get("total", "0"))
    except Exception:
        return _q("0")

def _supply_save_exact(x: Decimal | str | float) -> None:
    x = _q(x)
    try:
        pathlib.Path(DATA_DIR).mkdir(parents=True, exist_ok=True)
        pathlib.Path(CSOL_SUPPLY_FILE).write_text(json.dumps({"total": str(x)}))
    except Exception:
        pass

PENDING_BURN_FILE = os.path.join(DATA_DIR, "csol_pending_burn.json")

def _pending_burn_load() -> Decimal:
    try:
        j = json.loads(pathlib.Path(PENDING_BURN_FILE).read_text())
        return _q(j.get("amount", "0"))
    except Exception:
        return Decimal("0")

def _pending_burn_save(x: Decimal | str | float) -> None:
    try:
        pathlib.Path(PENDING_BURN_FILE).write_text(json.dumps({"amount": str(_q(x))}))
    except Exception:
        pass

def _pending_burn_add(x: Decimal | str | float) -> None:
    _pending_burn_save(_pending_burn_load() + _q(x))

def _write_temp_keypair_from_solders(kp) -> str:
    try:
        sk_bytes = kp.to_bytes()
    except Exception as e:
        raise RuntimeError(f"Cannot serialize Keypair: {e}")
    arr = list(sk_bytes)
    fd, tmp_path = tempfile.mkstemp(prefix="stealth_", suffix=".json")
    os.close(fd)
    with open(tmp_path, "w") as f:
        json.dump(arr, f)
    return tmp_path

def _spl_out(args: list[str]) -> str:
    # Increased timeout for blockchain transactions (especially with MPC)
    p = subprocess.run(args, capture_output=True, text=True, timeout=120)
    if p.returncode != 0:
        raise RuntimeError(p.stderr.strip() or "spl-token failed")
    return p.stdout.strip()

def _csol_supply_onchain() -> Decimal:
    out = _spl_out(["spl-token", "supply", ca.MINT])
    return _q(out.split()[0])

def _wrapper_ata() -> str:
    return ca.get_wrapper_ata()

def _wrapper_reserve_onchain() -> Decimal:
    try:
        out = _spl_out(["spl-token", "balance", _wrapper_ata()])
        return _q(out.split()[0])
    except Exception:
        return Decimal("0")

def ceil_to_100(x: Decimal) -> Decimal:
    x = Decimal(str(x))
    return ((x + Decimal("99")) // Decimal("100")) * Decimal("100")

def _resolve_treasury_keyfile() -> str:
    kf = TREASURY_KEYFILE or getattr(ca, "TREASURY_KEYPAIR", None)
    if not kf:
        raise HTTPException(status_code=500, detail="No treasury keyfile configured")
    return kf

def _resolve_treasury_pub_for_balance() -> str:
    return ca.get_pubkey_from_keypair(_resolve_treasury_keyfile())

def get_sol_vault_pda() -> str:
    """
    Derive the SOL_VAULT PDA address using Solana's PDA derivation.
    The SOL_VAULT is where all deposited SOL is stored.
    Seed: b"sol_vault"
    """
    from solders.pubkey import Pubkey

    program_id_str = os.getenv("INCOGNITO_PROG_ID", "4N49EyRoX9p9zoiv1weeeqpaJTGbEHizbzZVgrsrVQeC")
    program_id = Pubkey.from_string(program_id_str)

    pda, bump = Pubkey.find_program_address([b"sol_vault"], program_id)

    return str(pda)

def get_treasury_sol_balance() -> Decimal:
    """
    Get the balance of the SOL_VAULT (where all deposited SOL is stored).
    This is the backing for cSOL supply.
    """
    sol_vault_pub = get_sol_vault_pda()
    bal = ca.get_sol_balance(sol_vault_pub)
    return Decimal(str(bal or "0")).quantize(CSOL_DEC)

def _csol_total_supply_dec() -> Decimal:
    try:
        s = _csol_supply_onchain()
        _supply_save_exact(s)
        return s
    except Exception:
        return _supply_load()

def _csol_reserve_balance_dec() -> Decimal:
    return _wrapper_reserve_onchain()

def _apply_pending_balance(mint: str, ata: str, owner_kf: str, fee_payer_kf: str) -> None:
    _spl_out(
        [
            "spl-token",
            "apply-pending-balance",
            mint,
            "--address",
            ata,
            "--owner",
            owner_kf,
            "--fee-payer",
            fee_payer_kf,
        ]
    )

def _withdraw_confidential_tokens(
    mint: str,
    ata: str,
    owner_kf: str,
    fee_payer_kf: str,
    amount: Decimal,
) -> None:
    _spl_out(
        [
            "spl-token",
            "withdraw-confidential-tokens",
            mint,
            _fmt(amount),
            "--address",
            ata,
            "--owner",
            owner_kf,
            "--fee-payer",
            fee_payer_kf,
        ]
    )

def _burn_public_tokens_simple(ata: str, owner_kf: str, fee_payer_kf: str, amount: Decimal) -> None:
    _spl_out(
        [
            "spl-token",
            "burn",
            ata,
            _fmt(amount),
            "--owner",
            owner_kf,
            "--fee-payer",
            fee_payer_kf,
        ]
    )

def _burn_chunk(amount: Decimal) -> bool:
    """
    Try a simple public burn first.
    If that fails (likely all balance is confidential), then:
    apply-pending-balance -> withdraw-confidential-tokens -> burn.

    Uses a pool stealth fee payer (temp keyfile).
    """
    mint = ca.MINT
    ata = _wrapper_ata()
    owner_kf = ca.WRAPPER_KEYPAIR
    fee_tmp, _ = ca.pick_treasury_fee_payer_tmpfile()
    if not fee_tmp:
        return False
    try:
        try:
            _burn_public_tokens_simple(ata, owner_kf, fee_tmp, amount)
            return True
        except Exception:
            try:
                _apply_pending_balance(mint, ata, owner_kf, fee_tmp)
            except Exception:
                pass
            _withdraw_confidential_tokens(mint, ata, owner_kf, fee_tmp, amount)
            _burn_public_tokens_simple(ata, owner_kf, fee_tmp, amount)
            return True
    except Exception:
        return False
    finally:
        try:
            os.remove(fee_tmp)
        except Exception:
            pass

def _try_settle_pending_burn() -> None:
    pb = _pending_burn_load()
    if pb <= 0:
        return
    chunks = int(pb // CHUNK)
    if chunks <= 0:
        return
    settled = Decimal("0")
    for _ in range(chunks):
        ok = _burn_chunk(CHUNK)
        if not ok:
            break
        settled += CHUNK
    if settled > 0:
        _supply_save_exact(_csol_supply_onchain())
        _pending_burn_save(pb - settled)
        print(f"[PENDING_BURN] settled {settled}; remaining {pb - settled}")

def reconcile_csol_supply(assume_delta: Decimal = Decimal("0")) -> Dict[str, Any]:
    """
    Objectif: apr√®s l'op√©ration, la supply on-chain == target.
    - target = ceil_100(TreasurySOL + assume_delta), min 100
    - Mint/Burn par tranches fixes de 100
    """
    T = (get_treasury_sol_balance() + _q(assume_delta)).quantize(CSOL_DEC)
    target = max(Decimal("100"), ceil_to_100(T)).quantize(CSOL_DEC)
    S_on = _csol_total_supply_dec()
    gap = (S_on - target).quantize(CSOL_DEC)
    print(f"[RECONCILE] treasury={T} supply_onchain={S_on} target={target}")
    if gap == 0:
        _supply_save_exact(S_on)
        return {"action": "noop", "treasury": str(T), "target": str(target)}
    if gap > 0:
        chunks_needed = int(gap // CHUNK)
        burned = Decimal("0")
        for _ in range(chunks_needed):
            ok = _burn_chunk(CHUNK)
            if not ok:
                break
            burned += CHUNK
        if burned > 0:
            _supply_save_exact(_csol_supply_onchain())
            remaining = (Decimal(chunks_needed) * CHUNK) - burned
            if remaining > 0:
                _pending_burn_add(remaining)
                print(f"[RECONCILE] partial burn burned={burned} pending_burn+={remaining}")
                return {
                    "action": "partial_burn",
                    "amount": str(burned),
                    "pending": str(remaining),
                    "treasury": str(T),
                    "target": str(target),
                }
            print(f"[RECONCILE] BURN {burned} (100-lots)")
            return {"action": "burn", "amount": str(burned), "treasury": str(T), "target": str(target)}
    chunks_to_mint = int((-gap) // CHUNK)
    amt = _q(chunks_to_mint) * CHUNK
    print(f"[RECONCILE] MINT {amt} to wrapper reserve")
    ca.csol_mint_to_reserve(str(amt))
    _supply_save_exact(_csol_supply_onchain())
    return {"action": "mint", "amount": str(amt), "treasury": str(T), "target": str(target)}

def _ensure_reserve_has(amount: Decimal) -> None:
    """
    Garantir que la r√©serve poss√®de amount cSOL. Mint par tranches de 100 jusqu'√† couvrir le besoin.
    """
    amount = _q(amount)
    if amount <= 0:
        return
    reserve = _csol_reserve_balance_dec()
    print(f"[ENSURE_RESERVE] need={amount} reserve={reserve}")
    if reserve >= amount:
        print("[ENSURE_RESERVE] enough reserve, no mint")
        return
    missing = (amount - reserve).quantize(CSOL_DEC)
    chunks = int((missing + (CHUNK - Decimal("0.000000000"))) // CHUNK)
    if chunks <= 0:
        return
    to_mint = _q(chunks) * CHUNK
    print(f"[ENSURE_RESERVE] minting {to_mint}")
    ca.csol_mint_to_reserve(str(to_mint))
    _supply_save_exact(_csol_supply_onchain())

def _normalize_supply_on_startup():
    try:
        s = _csol_supply_onchain()
        _supply_save_exact(s)
        print(f"[STARTUP] mirrored on-chain supply: {s}")
    except Exception:
        pass

_normalize_supply_on_startup()

def _load_listing(listing_id: str) -> Dict[str, Any]:
    candidates = []
    try:
        from clients.cli import incognito_marketplace as mp
    except Exception:
        mp = None
    try:
        from services.api import listings as srv_listings
    except Exception:
        srv_listings = None
    if srv_listings:
        candidates += [
            getattr(srv_listings, n, None)
            for n in ("load_listing", "get_listing", "load_listing_by_id", "get_listing_by_id")
        ]
    if mp:
        candidates += [
            getattr(mp, n, None)
            for n in ("load_listing", "get_listing", "load_listing_by_id", "get_listing_by_id")
        ]
    for fn in candidates:
        if callable(fn):
            try:
                lst = fn(listing_id)
                if isinstance(lst, dict) and lst:
                    return lst
            except Exception:
                continue
    raise HTTPException(status_code=400, detail="Listing not found")

def _deactivate_listing(listing_id: str) -> None:
    candidates = []
    try:
        from services.api import listings as srv_listings
    except Exception:
        srv_listings = None
    try:
        from clients.cli import incognito_marketplace as mp
    except Exception:
        mp = None
    if srv_listings:
        candidates += [getattr(srv_listings, n, None) for n in ("deactivate_listing", "mark_sold", "set_inactive")]
    if mp:
        candidates += [getattr(mp, n, None) for n in ("deactivate_listing", "mark_sold", "set_inactive")]
    for fn in candidates:
        if callable(fn):
            try:
                fn(listing_id)
                return
            except Exception:
                continue
    return

@app.get("/admin/treasury")
def admin_treasury(keyfile: Optional[str] = None):
    kf = keyfile or _resolve_treasury_keyfile()
    pub = ca.get_pubkey_from_keypair(kf)
    bal = ca.get_sol_balance(pub)
    return {"keyfile": kf, "pub": pub, "balance_sol": str(Decimal(str(bal or 0)).quantize(CSOL_DEC))}

@app.post("/admin/reconcile")
def admin_reconcile():
    return reconcile_csol_supply()

@app.get("/metrics", response_model=List[MetricRow])
def metrics():
    rows = ev.metrics_all()
    return [MetricRow(epoch=r[0], issued_count=r[1], spent_count=r[2], updated_at=r[3]) for r in rows]

# ============================================================================
# HEALTH CHECK ENDPOINTS (Kubernetes-style)
# ============================================================================

@app.get("/health")
async def health():
    """
    Comprehensive health check endpoint

    Returns:
        - status: overall health status (healthy/unhealthy)
        - timestamp: current timestamp
        - checks: individual component health checks
    """
    from services.api.health_checks import comprehensive_health_check

    health_status = await comprehensive_health_check(
        database_enabled=DATABASE_ENABLED,
        rpc_url=SOLANA_RPC_URL if 'SOLANA_RPC_URL' in globals() else None
    )

    # Return 503 if unhealthy
    status_code = 200 if health_status["status"] == "healthy" else 503

    return JSONResponse(
        status_code=status_code,
        content=health_status
    )


@app.get("/health/ready")
async def readiness():
    """
    Readiness check endpoint (Kubernetes readiness probe)

    Returns 200 if ready to serve traffic, 503 otherwise
    """
    from services.api.health_checks import readiness_check

    is_ready = await readiness_check(
        database_enabled=DATABASE_ENABLED,
        rpc_url=SOLANA_RPC_URL if 'SOLANA_RPC_URL' in globals() else None
    )

    if is_ready:
        return {"status": "ready"}
    else:
        return JSONResponse(
            status_code=503,
            content={"status": "not_ready"}
        )


@app.get("/health/live")
async def liveness():
    """
    Liveness check endpoint (Kubernetes liveness probe)

    Returns 200 if alive, 503 otherwise
    """
    from services.api.health_checks import liveness_check

    is_alive = await liveness_check()

    if is_alive:
        return {"status": "alive"}
    else:
        return JSONResponse(
            status_code=503,
            content={"status": "dead"}
        )


@app.get("/database/health")
async def database_health():
    """
    Check database health and encryption status.

    Returns:
        - status: "healthy" or "unhealthy" or "disabled"
        - database_enabled: True/False
        - encryption_enabled: True/False (if database enabled)
        - connection_pool: Pool statistics (if database enabled)
    """
    if not DATABASE_ENABLED:
        return {
            "status": "disabled",
            "database_enabled": False,
            "message": "Database support not configured, using JSON file storage"
        }

    try:
        from services.database.config import health_check
        health = await health_check()
        return {
            "status": health["database"],
            "database_enabled": True,
            **health
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "database_enabled": True,
            "error": str(e)
        }


# ============================================================================
# DATABASE BACKUP ENDPOINTS
# ============================================================================

@app.post("/admin/backup/create")
async def create_backup(description: Optional[str] = None):
    """
    Create a manual database backup

    Args:
        description: Optional description for the backup

    Returns:
        Backup information (path, size, timestamp)
    """
    if not DATABASE_ENABLED:
        raise HTTPException(status_code=503, detail="Database not enabled")

    try:
        from services.database.backup import get_backup_manager

        backup_manager = get_backup_manager()
        if not backup_manager:
            raise HTTPException(status_code=503, detail="Backup system not initialized")

        backup_info = await backup_manager.create_backup(description=description)
        return backup_info

    except Exception as e:
        api_logger.error(f"Manual backup failed: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Backup failed: {str(e)}")


@app.get("/admin/backup/list")
async def list_backups():
    """
    List all available database backups

    Returns:
        List of backup information
    """
    if not DATABASE_ENABLED:
        raise HTTPException(status_code=503, detail="Database not enabled")

    try:
        from services.database.backup import get_backup_manager

        backup_manager = get_backup_manager()
        if not backup_manager:
            raise HTTPException(status_code=503, detail="Backup system not initialized")

        backups = await backup_manager.list_backups()
        return {"backups": backups, "count": len(backups)}

    except Exception as e:
        api_logger.error(f"Failed to list backups: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Failed to list backups: {str(e)}")


@app.get("/admin/backup/stats")
async def backup_stats():
    """
    Get database backup statistics

    Returns:
        Backup statistics (total count, size, oldest/newest)
    """
    if not DATABASE_ENABLED:
        raise HTTPException(status_code=503, detail="Database not enabled")

    try:
        from services.database.backup import get_backup_manager

        backup_manager = get_backup_manager()
        if not backup_manager:
            raise HTTPException(status_code=503, detail="Backup system not initialized")

        stats = await backup_manager.get_backup_stats()
        return stats

    except Exception as e:
        api_logger.error(f"Failed to get backup stats: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Failed to get backup stats: {str(e)}")


@app.post("/admin/backup/verify")
async def verify_backup():
    """
    Verify the most recent database backup

    Returns:
        Verification result
    """
    if not DATABASE_ENABLED:
        raise HTTPException(status_code=503, detail="Database not enabled")

    try:
        from services.database.backup import get_backup_manager

        backup_manager = get_backup_manager()
        if not backup_manager:
            raise HTTPException(status_code=503, detail="Backup system not initialized")

        is_valid = await backup_manager.verify_latest_backup()

        if is_valid:
            return {"status": "valid", "message": "Backup verification passed"}
        else:
            return JSONResponse(
                status_code=500,
                content={"status": "invalid", "message": "Backup verification failed"}
            )

    except Exception as e:
        api_logger.error(f"Backup verification failed: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Backup verification failed: {str(e)}")


@app.post("/admin/backup/restore")
async def restore_backup(
    filename: str,
    force: bool = False
):
    """
    Restore database from backup

    Args:
        filename: Backup filename to restore
        force: Force restore without safety backup

    Returns:
        Restoration result

    WARNING: This will overwrite the current database!
    """
    if not DATABASE_ENABLED:
        raise HTTPException(status_code=503, detail="Database not enabled")

    try:
        from services.database.backup import get_backup_manager

        backup_manager = get_backup_manager()
        if not backup_manager:
            raise HTTPException(status_code=503, detail="Backup system not initialized")

        api_logger.warning(f"Database restore requested: {filename}")

        success = await backup_manager.restore_backup(filename, force=force)

        if success:
            return {"status": "success", "message": f"Database restored from {filename}"}
        else:
            raise HTTPException(status_code=500, detail="Restore failed")

    except FileNotFoundError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        api_logger.error(f"Database restore failed: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Restore failed: {str(e)}")

@app.get("/merkle/status", response_model=MerkleStatus)
def merkle_status():
    wst = ca.load_wrapper_state()
    wmt = ca.build_merkle(wst)
    if not wmt.layers and getattr(wmt, "leaf_bytes", None):
        wmt.build_tree()
    total = Decimal("0")
    for n in wst.get("notes", []):
        if not n.get("spent", False):
            try:
                total += Decimal(str(n["amount"]))
            except Exception:
                pass
    pst = ca.load_pool_state()
    pmt = OldMerkleTree([r["commitment"] for r in pst.get("records", [])])
    if not pmt.layers and getattr(pmt, "leaf_bytes", None):
        pmt.build_tree()
    return MerkleStatus(
        wrapper_leaves=len(wst.get("leaves", [])),
        wrapper_root_hex=wmt.root().hex(),
        wrapper_nullifiers=len(wst.get("nullifiers", [])),
        wrapper_unspent_total_sol=ca.fmt_amt(total),
        pool_records=len(pst.get("records", [])),
        pool_root_hex=pmt.root().hex(),
    )

@app.post("/pool-state-reset")
def pool_state_reset():
    """
    Reset local pool state (WARNING: This will clear your local tree!)
    Only use this if you know what you're doing.
    """
    import time
    import shutil

    pool_merkle_path = Path(REPO_ROOT) / "pool_merkle_state.json"
    backup_path = Path(REPO_ROOT) / f"pool_merkle_state.backup.{int(time.time())}.json"

    if pool_merkle_path.exists():
        shutil.copy(pool_merkle_path, backup_path)

        with open(pool_merkle_path, 'w') as f:
            json.dump({
                "depth": MERKLE_TREE_DEPTH,
                "leaves": [],
                "leaf_count": 0
            }, f, indent=2)

        return {"success": True, "message": f"Local state reset. Backup saved to {backup_path.name}"}
    else:
        return {"success": False, "message": "No local state found"}

@app.get("/pool-state-debug")
def pool_state_debug(cluster: str = "localnet"):
    """
    Debug endpoint to compare local vs on-chain pool state
    """
    pool_merkle_path = Path(REPO_ROOT) / "pool_merkle_state.json"
    if not pool_merkle_path.exists():
        return {"error": "No local pool state found"}

    with open(pool_merkle_path, 'r') as f:
        local_state = json.load(f)

    tree = PoolMerkleTree(depth=MERKLE_TREE_DEPTH)
    for leaf_hex in local_state.get("leaves", []):
        tree.insert(bytes.fromhex(leaf_hex))

    local_root = tree.root().hex()
    local_leaf_count = len(tree.leaves)

    try:
        from services.crypto_core.onchain_pool import get_onchain_pool_state
        onchain_state = get_onchain_pool_state(cluster=cluster)

        return {
            "local": {
                "root": local_root,
                "leaf_count": local_leaf_count,
                "depth": tree.depth
            },
            "onchain": onchain_state,
            "synchronized": local_root == onchain_state["root"] and local_leaf_count == onchain_state["leaf_count"]
        }
    except Exception as e:
        return {
            "local": {
                "root": local_root,
                "leaf_count": local_leaf_count,
                "depth": tree.depth
            },
            "onchain_error": str(e)
        }

@app.post("/deposit", response_model=DepositRes)
async def deposit(req: DepositReq):
    """
    Deposit SOL to the on-chain incognito pool.

    This creates a commitment, deposits to the pool, and generates a wrapper stealth
    address for the 0.05 SOL fee. The depositor receives back the secret/nullifier
    needed to later withdraw.
    """
    amount_lamports = int(req.amount_sol * 1_000_000_000)

    if amount_lamports <= 50_000_000:
        raise HTTPException(
            status_code=400,
            detail="Deposit amount must be greater than 0.05 SOL (wrapper fee)"
        )

    pool_merkle_path = Path(REPO_ROOT) / "pool_merkle_state.json"
    if pool_merkle_path.exists():
        with open(pool_merkle_path, 'r') as f:
            pool_state = json.load(f)
        tree = PoolMerkleTree(depth=MERKLE_TREE_DEPTH)
        for leaf_hex in pool_state.get("leaves", []):
            tree.insert(bytes.fromhex(leaf_hex))
    else:
        tree = PoolMerkleTree(depth=MERKLE_TREE_DEPTH)

    secret = secrets.token_bytes(32)
    nullifier = secrets.token_bytes(32)

    commitment, nf_hash, merkle_path = prepare_deposit_params(
        amount_lamports=amount_lamports,
        secret=secret,
        nullifier=nullifier,
        local_merkle_tree=tree
    )

    # Validate and sanitize keyfile path (prevents path traversal)
    try:
        depositor_keyfile = validate_keyfile_path(
            req.depositor_keyfile,
            allowed_dirs=["keys", "test_keys", ".keys"],
            repo_root=REPO_ROOT
        )
    except ValidationError as e:
        raise HTTPException(
            status_code=400,
            detail=f"Invalid depositor keyfile path: {str(e)}"
        )

    if not os.path.exists(depositor_keyfile):
        raise HTTPException(
            status_code=400,
            detail=f"Depositor keyfile not found at {depositor_keyfile}"
        )

    wrapper_keyfile = ca.WRAPPER_KEYPAIR
    if not os.path.isabs(wrapper_keyfile):
        wrapper_keyfile = os.path.join(REPO_ROOT, wrapper_keyfile)

    if not os.path.exists(wrapper_keyfile):
        raise HTTPException(
            status_code=500,
            detail=f"Wrapper keyfile not found at {wrapper_keyfile}"
        )

    try:
        result = deposit_to_pool_onchain(
            depositor_keyfile=depositor_keyfile,
            amount_lamports=amount_lamports,
            commitment=commitment,
            nf_hash=nf_hash,
            merkle_path=merkle_path,
            wrapper_keyfile=wrapper_keyfile,
            wrapper_stealth_state_path=WRAPPER_STEALTH_STATE_PATH,
            cluster=req.cluster
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Deposit failed: {str(e)}")

    leaf = h2(commitment, nf_hash)
    tree.insert(leaf)
    leaf_index = len(tree.leaves) - 1

    with open(pool_merkle_path, 'w') as f:
        json.dump({
            "depth": tree.depth,
            "leaves": [leaf.hex() for leaf in tree.leaves],
            "leaf_count": len(tree.leaves)
        }, f, indent=2)

    result["secret"] = secret.hex()
    result["nullifier"] = nullifier.hex()
    result["commitment"] = commitment.hex()
    result["leaf_index"] = leaf_index

    # Store deposit note in DATABASE with client-side encryption
    depositor_pub = ca.get_pubkey_from_keypair(depositor_keyfile)

    from services.crypto_core.client_encryption import encrypt_note_from_keypair_file

    note_data = {
        "secret": secret.hex(),
        "nullifier": nullifier.hex(),
        "commitment": commitment.hex(),
        "leaf_index": leaf_index,
        "amount_sol": float(req.amount_sol) - 0.05,  # Subtract wrapper fee
    }

    encrypted_blob = encrypt_note_from_keypair_file(note_data, depositor_keyfile)

    await _save_note_for_user_db(
        owner_pub=depositor_pub,
        encrypted_blob=encrypted_blob,
        commitment=commitment.hex(),
        tx_signature=result.get("tx_signature", ""),
        spent=False
    )

    print(f"[DEPOSIT] Note encrypted and saved in DATABASE for {depositor_pub[:8]}...")

    return DepositRes(**result)


@app.post("/notes/store")
async def store_encrypted_note(req: dict):
    """
    Store a client-side encrypted note in the database.

    The client encrypts the note with their Solana keypair before sending.
    The API server is BLIND - it cannot decrypt this data.

    Request format:
    {
        "owner_pubkey": "...",
        "commitment": "...",
        "encrypted_blob": {"ciphertext": "...", "nonce": "..."},
        "tx_signature": "..."
    }
    """
    try:
        owner_pub = req["owner_pubkey"]
        commitment = req["commitment"]
        encrypted_blob = req["encrypted_blob"]
        tx_signature = req.get("tx_signature", "")

        await _save_note_for_user_db(
            owner_pub=owner_pub,
            encrypted_blob=encrypted_blob,
            commitment=commitment,
            tx_signature=tx_signature,
            spent=False
        )

        return {"ok": True, "message": "Note stored successfully"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to store note: {str(e)}")


@app.get("/notes/{owner_pub}")
async def list_notes(owner_pub: str):
    """
    Get all encrypted notes for a user (CLIENT-SIDE ENCRYPTED).

    Returns encrypted blobs that only the user can decrypt with their private key.
    The API server CANNOT see the note contents (secret, nullifier, amount).

    Response format:
    {
        "ok": true,
        "notes": [
            {
                "commitment": "...",
                "encrypted_blob": {"ciphertext": "...", "nonce": "..."},
                "spent": false,
                "created_at": "2025-01-04T..."
            }
        ]
    }

    The client must decrypt each encrypted_blob locally to get:
    - secret
    - nullifier
    - amount_sol
    - leaf_index
    """
    notes = await _get_user_notes_db(owner_pub, include_spent=False)

    return {
        "ok": True,
        "notes": notes  # Returns encrypted blobs
    }

@app.post("/withdraw", response_model=WithdrawRes)
async def withdraw(req: WithdrawReq):
    """
    Withdraw SOL from the on-chain incognito pool.

    PRIVACY: User provides their own note credentials (secret, nullifier, commitment).
    No server-side tracking of who owns what. Anyone with valid credentials can withdraw.
    """
    # Validate and sanitize keyfile path (prevents path traversal)
    try:
        recipient_keyfile = validate_keyfile_path(
            req.recipient_keyfile,
            allowed_dirs=["keys", "test_keys", ".keys"],
            repo_root=REPO_ROOT
        )
    except ValidationError as e:
        raise HTTPException(
            status_code=400,
            detail=f"Invalid recipient keyfile path: {str(e)}"
        )

    if not os.path.exists(recipient_keyfile):
        raise HTTPException(
            status_code=400,
            detail=f"Recipient keyfile not found at {recipient_keyfile}"
        )

    amount_lamports = int(req.amount_sol * 1_000_000_000)
    deposited_amount_lamports = int(req.deposited_amount_sol * 1_000_000_000)

    is_partial = amount_lamports < deposited_amount_lamports
    change_lamports = deposited_amount_lamports - amount_lamports if is_partial else 0

    if is_partial and change_lamports <= 50_000_000:
        raise HTTPException(
            status_code=400,
            detail=f"Change amount ({change_lamports / 1_000_000_000:.2f} SOL) is too small. Remaining balance must be > 0.05 SOL for wrapper fee."
        )

    try:
        commitment = bytes.fromhex(req.commitment)
        nullifier = bytes.fromhex(req.nullifier)
        secret = bytes.fromhex(req.secret)
    except ValueError as e:
        raise HTTPException(status_code=400, detail=f"Invalid hex input: {e}")

    if len(commitment) != 32 or len(nullifier) != 32 or len(secret) != 32:
        raise HTTPException(
            status_code=400,
            detail="Commitment, nullifier, and secret must be 32 bytes each"
        )

    # CRITICAL: Sync local tree with on-chain state before withdrawal
    print(f"[WITHDRAW] Syncing local tree with on-chain state...")

    import subprocess
    deposit_history_script = Path(REPO_ROOT) / "contracts" / "incognito" / "scripts" / "get_deposit_history.ts"

    env = os.environ.copy()
    env["ANCHOR_PROVIDER_URL"] = "http://localhost:8899"
    env["ANCHOR_WALLET"] = str(Path(REPO_ROOT) / "keys" / "wrapper.json")

    try:
        result = subprocess.run(
            ["npx", "tsx", str(deposit_history_script)],
            cwd=deposit_history_script.parent.parent,
            env=env,
            capture_output=True,
            text=True,
            timeout=30
        )

        if result.returncode == 0:
            notes = json.loads(result.stdout)
            synced_leaves = []
            for note in notes:
                commitment_bytes = bytes.fromhex(note["commitment"])
                nf_hash_bytes = bytes.fromhex(note["nf_hash"])
                leaf = h2(commitment_bytes, nf_hash_bytes)
                synced_leaves.append(leaf.hex())

            print(f"[WITHDRAW] Fetched {len(synced_leaves)} leaves from on-chain")

            # Fallback to local file if on-chain history is empty
            if len(synced_leaves) == 0:
                print(f"[WITHDRAW] ‚ö†Ô∏è  On-chain history empty, using local pool_merkle_state.json")
                pool_merkle_path = Path(REPO_ROOT) / "pool_merkle_state.json"
                if pool_merkle_path.exists():
                    with open(pool_merkle_path, 'r') as f:
                        local_state = json.load(f)
                    synced_leaves = local_state.get("leaves", [])
                    print(f"[WITHDRAW] Loaded {len(synced_leaves)} leaves from local file")
                else:
                    raise HTTPException(500, "No Merkle tree state available (neither on-chain nor local)")

            # Save synced state to local file
            # IMPORTANT: Use depth 10 to match on-chain contract
            pool_merkle_path = Path(REPO_ROOT) / "pool_merkle_state.json"
            with open(pool_merkle_path, 'w') as f:
                json.dump({
                    "depth": 10,  # Must match on-chain depth
                    "leaves": synced_leaves,
                    "leaf_count": len(synced_leaves)
                }, f, indent=2)

            print(f"[WITHDRAW] ‚úÖ Local tree synced with {len(synced_leaves)} leaves")

    except Exception as e:
        print(f"[WITHDRAW] ‚ö†Ô∏è  Could not sync with on-chain, using local file: {e}")
        # Continue with local file

    # Load the (now synced) local tree
    pool_merkle_path = Path(REPO_ROOT) / "pool_merkle_state.json"
    if not pool_merkle_path.exists():
        raise HTTPException(
            status_code=500,
            detail="Pool Merkle state not found. Have you made any deposits?"
        )

    with open(pool_merkle_path, 'r') as f:
        pool_state = json.load(f)

    tree = PoolMerkleTree(depth=MERKLE_TREE_DEPTH)
    for leaf_hex in pool_state.get("leaves", []):
        tree.insert(bytes.fromhex(leaf_hex))

    print(f"[WITHDRAW] Local tree has {len(tree.leaves)} leaves")

    leaf_index = req.leaf_index

    # Compute expected leaf from user's note
    nf_hash = h1(nullifier)
    expected_leaf = h2(commitment, nf_hash)

    # Validate leaf_index is within bounds
    if leaf_index >= len(tree.leaves):
        # Try to find the note in the tree at a different index
        print(f"[WITHDRAW] ‚ö†Ô∏è  Claimed leaf_index {leaf_index} out of bounds, searching tree...")
        for idx, leaf in enumerate(tree.leaves):
            if leaf == expected_leaf:
                print(f"[WITHDRAW] Found note at index {idx} instead of claimed {leaf_index}")
                leaf_index = idx
                break
        else:
            raise HTTPException(
                status_code=400,
                detail=f"Note not found in tree. Tree has {len(tree.leaves)} leaves, claimed index {leaf_index}"
            )

    # Verify the leaf at this index matches the user's note
    actual_leaf = tree.leaves[leaf_index]
    if expected_leaf != actual_leaf:
        # Search for the correct index
        print(f"[WITHDRAW] ‚ö†Ô∏è  Leaf mismatch at index {leaf_index}, searching tree...")
        for idx, leaf in enumerate(tree.leaves):
            if leaf == expected_leaf:
                print(f"[WITHDRAW] Found note at index {idx} instead of {leaf_index}")
                leaf_index = idx
                actual_leaf = tree.leaves[leaf_index]
                break
        else:
            raise HTTPException(
                status_code=400,
                detail=f"Note with commitment {commitment.hex()[:16]}... not found in tree"
            )

    print(f"[WITHDRAW] Using note at leaf_index {leaf_index}")
    merkle_path = tree.get_path(leaf_index)

    change_commitment = None
    change_nf_hash = None
    change_merkle_path_data = None
    change_secret = None
    change_nullifier = None

    if is_partial:
        print(f"Partial withdrawal detected: preparing change note for {change_lamports / 1_000_000_000:.2f} SOL")

        change_secret = secrets.token_bytes(32)
        change_nullifier = secrets.token_bytes(32)

        change_commitment, change_nf_hash, change_merkle_path_data = prepare_deposit_params(
            amount_lamports=change_lamports,
            secret=change_secret,
            nullifier=change_nullifier,
            local_merkle_tree=tree
        )

    try:
        result = withdraw_from_pool_onchain(
            recipient_keyfile=recipient_keyfile,
            amount_lamports=amount_lamports,
            commitment=commitment,
            nullifier=nullifier,
            leaf_index=leaf_index,
            merkle_path=merkle_path,
            change_commitment=change_commitment,
            change_nf_hash=change_nf_hash,
            change_merkle_path=change_merkle_path_data,
            cluster=req.cluster
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Withdrawal failed: {str(e)}")

    recipient_pub = get_pubkey_from_keypair(recipient_keyfile)
    await _mark_note_spent_db(req.commitment, req.nullifier, recipient_pub)

    change_note_data = None
    if is_partial and change_commitment is not None:
        print(f" Partial withdrawal successful! Updating local tree with change note...")

        change_leaf = h2(change_commitment, change_nf_hash)
        tree.insert(change_leaf)
        change_leaf_index = len(tree.leaves) - 1

        with open(pool_merkle_path, 'w') as f:
            json.dump({
                "depth": tree.depth,
                "leaves": [leaf.hex() for leaf in tree.leaves],
                "leaf_count": len(tree.leaves)
            }, f, indent=2)

        change_note_data = {
            "secret": change_secret.hex(),
            "nullifier": change_nullifier.hex(),
            "commitment": change_commitment.hex(),
            "leaf_index": change_leaf_index,
            "amount_sol": change_lamports / 1_000_000_000,
            "tx_signature": result["tx_signature"]
        }

        # Store withdrawal change note in DATABASE with client-side encryption
        from services.crypto_core.client_encryption import encrypt_note_from_keypair_file

        change_note_plaintext = {
            "secret": change_secret.hex(),
            "nullifier": change_nullifier.hex(),
            "commitment": change_commitment.hex(),
            "leaf_index": change_leaf_index,
            "amount_sol": change_lamports / 1_000_000_000,
        }

        encrypted_blob = encrypt_note_from_keypair_file(change_note_plaintext, recipient_keyfile)

        await _save_note_for_user_db(
            owner_pub=recipient_pub,
            encrypted_blob=encrypted_blob,
            commitment=change_commitment.hex(),
            tx_signature=result["tx_signature"],
            spent=False
        )

        print(f" Change note created, saved to DATABASE, and returned to client. Leaf index: {change_leaf_index}")

    if change_note_data:
        result["change_note"] = change_note_data

    return WithdrawRes(**result)

@app.get("/stealth/{owner_pub}", response_model=StealthList)
def list_stealth(owner_pub: str, include_balances: bool = True, min_sol: float = 0.01):
    pst = ca.load_pool_state()
    recs = [r for r in pst.get("records", []) if r.get("owner_pubkey") == owner_pub]
    items, total = [], Decimal("0")
    for r in recs:
        bal_str = None
        if include_balances:
            try:
                b = Decimal(str(ca.get_sol_balance(r["stealth_pubkey"], quiet=True)))
                if b < Decimal(str(min_sol)):
                    continue
                bal_str = ca.fmt_amt(b)
                total += b
            except Exception:
                pass
        items.append(
            StealthItem(
                stealth_pubkey=r["stealth_pubkey"],
                eph_pub_b58=r["eph_pub_b58"],
                counter=int(r["counter"]),
                balance_sol=bal_str,
            )
        )
    return StealthList(
        owner_pub=owner_pub, items=items, total_sol=(ca.fmt_amt(total) if include_balances else None)
    )

@app.post("/sweep", response_model=SweepRes)
def sweep(req: SweepReq):
    pst = ca.load_pool_state()
    recs = [r for r in pst.get("records", []) if r.get("owner_pubkey") == req.owner_pub]
    if not recs:
        raise HTTPException(status_code=400, detail="No stealth records for owner")
    SWEEP_BUFFER_SOL = Decimal("0.001")
    candidates = []
    total_balance = Decimal("0")
    if req.stealth_pubkeys:
        allowed = set(req.stealth_pubkeys)
        recs = [r for r in recs if r.get("stealth_pubkey") in allowed]
        if not recs:
            raise HTTPException(
                status_code=400, detail="None of the requested stealth addresses are owned by this owner"
            )
    for r in recs:
        try:
            b = Decimal(str(ca.get_sol_balance(r["stealth_pubkey"], quiet=True)))
        except Exception:
            b = Decimal("0")
        if b >= SWEEP_BUFFER_SOL:
            candidates.append({**r, "balance": b})
        total_balance += b
    if total_balance <= 0:
        raise HTTPException(status_code=400, detail="No sweepable balances (all below buffer)")
    req_amt = total_balance if req.amount_sol is None else Decimal(req.amount_sol)
    candidates.sort(key=lambda x: x["balance"], reverse=True)
    plan, remain = [], req_amt
    for r in candidates:
        if remain <= 0:
            break
        sendable = (r["balance"] - SWEEP_BUFFER_SOL).quantize(
            Decimal("0.000000001"), rounding=ROUND_DOWN
        )
        if sendable <= 0:
            continue
        amt = min(sendable, remain)
        if amt > 0:
            plan.append((r["stealth_pubkey"], r["eph_pub_b58"], amt, r.get("counter", 0)))
            remain = (remain - amt).quantize(Decimal("0.000000001"), rounding=ROUND_DOWN)
    with open(req.secret_keyfile, "r") as f:
        raw_secret = json.load(f)
    rec_sk64 = ca.read_secret_64_from_json_value(raw_secret)
    sent_total, txs = Decimal("0"), []
    for stealth_addr, eph, amt, counter in plan:
        kp = ca.derive_stealth_from_recipient_secret(rec_sk64, eph, counter)
        tmp_path = _write_temp_keypair_from_solders(kp)
        try:
            tx_out = ca.solana_transfer(tmp_path, req.dest_pub, ca.fmt_amt(amt))
            txs.append(tx_out)
            sent_total += amt
        finally:
            try:
                os.remove(tmp_path)
            except Exception:
                pass
    try:
        ca.emit("SweepDone", owner_pub=req.owner_pub, count=len(plan))
    except Exception:
        pass
    return SweepRes(requested=ca.fmt_amt(req_amt), sent_total=ca.fmt_amt(sent_total), txs=txs)

@app.post("/marketplace/buy", response_model=BuyRes)
async def marketplace_buy(req: BuyReq):
    """
    Buy a listing using privacy pool notes - NO on-chain transaction.

    Flow:
    1. Validate buyer's note credentials
    2. Mark buyer's note as spent in database
    3. Create escrow record in database (funds held virtually)
    4. When escrow completes, seller generates payment note CLIENT-SIDE
    5. NO cSOL, NO ATA, NO confidential transfers - pure note-based system
    """
    # Validate buyer keyfile path (prevents path traversal)
    try:
        buyer_keyfile_validated = validate_keyfile_path(
            req.buyer_keyfile,
            allowed_dirs=["keys", "test_keys", ".keys"],
            repo_root=REPO_ROOT
        )
    except ValidationError as e:
        raise HTTPException(
            status_code=400,
            detail=f"Invalid buyer keyfile path: {str(e)}"
        )

    buyer_pub = ca.get_pubkey_from_keypair(buyer_keyfile_validated)
    listing = ca.listing_get(req.listing_id)
    if not listing:
        raise HTTPException(400, "Listing not found")

    unit_price = Decimal(
        str(
            listing.get("unit_price_sol")
            or listing.get("price")
            or listing.get("amount_sol")
            or "0"
        )
    ).quantize(CSOL_DEC)

    qty = int(req.quantity)
    if qty <= 0:
        raise HTTPException(400, "Quantity must be >= 1")

    total_price = (unit_price * Decimal(qty)).quantize(CSOL_DEC)
    seller_pub = listing.get("seller_pub") or listing.get("seller") or listing.get("owner_pub")

    if not seller_pub:
        raise HTTPException(400, "Listing missing seller_pub")
    if seller_pub == buyer_pub:
        raise HTTPException(400, "Cannot buy your own listing")

    has_note_credentials = (
        req.commitment and len(req.commitment) > 0 and
        req.nullifier and len(req.nullifier) > 0 and
        req.secret and len(req.secret) > 0
    )

    if has_note_credentials:
        deposited_amount = Decimal(str(req.deposited_amount_sol or "0")).quantize(CSOL_DEC)
        WRAPPER_FEE_SOL = Decimal("0.05")
        withdrawable_amount = (deposited_amount - WRAPPER_FEE_SOL).quantize(CSOL_DEC)

        if withdrawable_amount < total_price:
            raise HTTPException(
                400,
                f"Insufficient note amount: {withdrawable_amount} SOL < {total_price} SOL required"
            )

        try:
            amount_lamports = int(total_price * 1_000_000_000)
            withdrawable_lamports = int(withdrawable_amount * 1_000_000_000)

            commitment = bytes.fromhex(req.commitment)
            nullifier = bytes.fromhex(req.nullifier)
            secret = bytes.fromhex(req.secret)

            if len(commitment) != 32 or len(nullifier) != 32 or len(secret) != 32:
                raise HTTPException(400, "Invalid note credentials: must be 32 bytes each")

            pool_merkle_path = Path(REPO_ROOT) / "pool_merkle_state.json"
            if not pool_merkle_path.exists():
                raise HTTPException(500, "Pool Merkle state not found")

            with open(pool_merkle_path, 'r') as f:
                pool_state = json.load(f)

            from services.crypto_core.onchain_pool import (
                MerkleTree as PoolMerkleTree,
                h1, h2,
            )

            tree = PoolMerkleTree(depth=MERKLE_TREE_DEPTH)
            for leaf_hex in pool_state.get("leaves", []):
                tree.insert(bytes.fromhex(leaf_hex))

            if req.leaf_index >= len(tree.leaves):
                raise HTTPException(400, f"Invalid leaf_index {req.leaf_index}")

            nf_hash = h1(nullifier)
            expected_leaf = h2(commitment, nf_hash)
            actual_leaf = tree.leaves[req.leaf_index]

            if expected_leaf != actual_leaf:
                raise HTTPException(400, "Note credentials don't match on-chain leaf")

        except Exception as e:
            raise HTTPException(500, f"Note validation failed: {str(e)}")

        # Mark buyer's note as spent in database
        print(f"[PURCHASE] Marking buyer's note as spent...")
        await _mark_note_spent_db(req.commitment, req.nullifier, buyer_pub)
        print(f"[PURCHASE] ‚úÖ Buyer's note marked as spent")

    change_note_data = None

    # Create change note if buyer paid more than the purchase price
    if has_note_credentials and withdrawable_amount > total_price:
        change_amount = withdrawable_amount - total_price
        print(f"[PURCHASE] Creating change note for {change_amount} SOL...")

        from services.crypto_core.onchain_pool import h1, h2, MerkleTree as PoolMerkleTree
        import subprocess

        # Generate new credentials for change note
        change_secret = secrets.token_bytes(32)
        change_nullifier = secrets.token_bytes(32)
        change_commitment = h2(change_secret, change_nullifier)
        change_nf_hash = h1(change_nullifier)

        print(f"[PURCHASE] Adding change note to on-chain Merkle tree...")

        # Fetch current on-chain tree state
        deposit_history_script = Path(REPO_ROOT) / "contracts" / "incognito" / "scripts" / "get_deposit_history.ts"

        env = os.environ.copy()
        env["ANCHOR_PROVIDER_URL"] = "http://localhost:8899"
        env["ANCHOR_WALLET"] = str(Path(REPO_ROOT) / "keys" / "wrapper.json")

        try:
            result = subprocess.run(
                ["npx", "tsx", str(deposit_history_script)],
                cwd=deposit_history_script.parent.parent,
                env=env,
                capture_output=True,
                text=True,
                timeout=30
            )

            if result.returncode == 0:
                # Parse JSON from stdout (stderr contains logs)
                try:
                    notes = json.loads(result.stdout)
                    existing_leaves = []
                    for note in notes:
                        commitment_bytes = bytes.fromhex(note["commitment"])
                        nf_hash_bytes = bytes.fromhex(note["nf_hash"])
                        leaf = h2(commitment_bytes, nf_hash_bytes)
                        existing_leaves.append(leaf.hex())

                    print(f"[PURCHASE] Fetched {len(existing_leaves)} existing leaves from on-chain")

                    # Fallback to local file if on-chain history is empty (e.g., localnet restarted)
                    if len(existing_leaves) == 0:
                        print(f"[PURCHASE] ‚ö†Ô∏è  On-chain history empty, using local pool_merkle_state.json")
                        pool_merkle_path = Path(REPO_ROOT) / "pool_merkle_state.json"
                        if pool_merkle_path.exists():
                            with open(pool_merkle_path, 'r') as f:
                                local_state = json.load(f)
                            existing_leaves = local_state.get("leaves", [])
                            print(f"[PURCHASE] Loaded {len(existing_leaves)} leaves from local file")

                except json.JSONDecodeError as json_err:
                    print(f"[PURCHASE] ‚ùå JSON parse error: {json_err}")
                    print(f"[PURCHASE] stdout: {result.stdout[:200]}")
                    print(f"[PURCHASE] stderr: {result.stderr[:200]}")
                    raise HTTPException(500, f"Failed to parse on-chain state: {json_err}")
            else:
                print(f"[PURCHASE] ‚ùå get_deposit_history failed:")
                print(f"[PURCHASE]   stdout: {result.stdout}")
                print(f"[PURCHASE]   stderr: {result.stderr}")
                raise HTTPException(500, f"Failed to fetch on-chain state: {result.stderr}")
        except subprocess.TimeoutExpired:
            raise HTTPException(500, "Timeout fetching on-chain state")
        except Exception as e:
            print(f"[PURCHASE] ‚ùå Error fetching on-chain state: {e}")
            raise

        # Call add_claim_note.ts to add change note to on-chain tree
        add_note_script = Path(REPO_ROOT) / "contracts" / "incognito" / "scripts" / "add_claim_note.ts"
        existing_leaves_csv = ",".join(existing_leaves) if existing_leaves else ""

        try:
            result = subprocess.run(
                ["npx", "tsx", str(add_note_script), change_commitment.hex(), change_nf_hash.hex(), existing_leaves_csv],
                cwd=add_note_script.parent.parent,
                env=env,
                capture_output=True,
                text=True,
                timeout=30
            )

            if result.returncode != 0:
                raise RuntimeError(f"Failed to add change note on-chain: {result.stderr}")

            output = json.loads(result.stdout)
            if not output.get("success"):
                raise RuntimeError(f"add_claim_note failed: {output.get('error', 'Unknown error')}")

            change_leaf_index = output["index"]
            change_tx_signature = output["tx"]

            print(f"[PURCHASE] ‚úÖ Change note added to on-chain tree at index {change_leaf_index}")

        except Exception as e:
            raise HTTPException(500, f"Failed to add change note to on-chain tree: {str(e)}")

        # Update local tree from on-chain state
        pool_merkle_path = Path(REPO_ROOT) / "pool_merkle_state.json"
        tree = PoolMerkleTree(depth=MERKLE_TREE_DEPTH)

        # Add all existing leaves from on-chain
        for leaf_hex in existing_leaves:
            tree.insert(bytes.fromhex(leaf_hex))

        # Add the new change note leaf
        change_leaf = h2(change_commitment, change_nf_hash)
        tree.insert(change_leaf)

        # Save updated tree
        with open(pool_merkle_path, 'w') as f:
            json.dump({
                "depth": tree.depth,
                "leaves": [leaf.hex() for leaf in tree.leaves],
                "leaf_count": len(tree.leaves)
            }, f, indent=2)

        change_note_data = {
            "secret": change_secret.hex(),
            "nullifier": change_nullifier.hex(),
            "commitment": change_commitment.hex(),
            "leaf_index": change_leaf_index,
            "amount_sol": float(change_amount),
            "tx_signature": change_tx_signature
        }

        # Store change note in DATABASE with client-side encryption
        from services.crypto_core.client_encryption import encrypt_note_from_keypair_file

        change_note_plaintext = {
            "secret": change_secret.hex(),
            "nullifier": change_nullifier.hex(),
            "commitment": change_commitment.hex(),
            "leaf_index": change_leaf_index,
            "amount_sol": float(change_amount),
        }

        encrypted_blob = encrypt_note_from_keypair_file(change_note_plaintext, buyer_keyfile_validated)

        await _save_note_for_user_db(
            owner_pub=buyer_pub,
            encrypted_blob=encrypted_blob,
            commitment=change_commitment.hex(),
            tx_signature=change_tx_signature,
            spent=False
        )

        print(f"[PURCHASE] ‚úÖ Change note created, synced, and saved in DATABASE for buyer")

    encrypted_shipping_blob: Optional[Dict[str, Any]] = getattr(req, "encrypted_shipping", None)
    order_id: Optional[str] = None
    if isinstance(encrypted_shipping_blob, dict):
        order_id = secrets.token_hex(16)

    escrow_id = secrets.token_hex(16)

    # NOTE-BASED SYSTEM: No on-chain transaction, no cSOL, no ATA
    # Simply mark the buyer's note as spent in database and create escrow record
    print(f"[PURCHASE] Note-based purchase - NO on-chain transaction")
    print(f"[PURCHASE] Buyer commits {total_price} SOL from their note")
    print(f"[PURCHASE] Seller will generate payment note CLIENT-SIDE when escrow completes")

    # NO escrow_create_order, NO reconcile_csol_supply, NO ATA operations
    # Funds are held "virtually" - seller gets payment note credentials when buyer releases

    try:
        ca.listing_update_quantity(seller_pub, req.listing_id, quantity_delta=-qty)
    except Exception:
        _deactivate_listing(req.listing_id)

    shipping_commitment = None
    if isinstance(encrypted_shipping_blob, dict):
        try:
            proof = _shipping_append_event(
                order_id=order_id or secrets.token_hex(16),
                listing_id=req.listing_id,
                buyer_pub=buyer_pub,
                seller_pub=seller_pub,
                encrypted_blob=encrypted_shipping_blob,
            )
            shipping_commitment = proof
        except Exception:
            shipping_commitment = None

    amount_str = _fmt(total_price)
    note_hex, nonce_hex, commitment_hex = _mk_escrow_commitment(amount_str, seller_pub)
    leaf_index = _escrow_append_leaf(commitment_hex)

    st_esc = _escrow_state()
    now = _utcnow_iso()
    escrow_record = {
        "id": escrow_id,
        "buyer_pub": buyer_pub,
        "seller_pub": seller_pub,
        "amount_sol": amount_str,
        "status": "CREATED",
        "details_ct": None,
        "listing_id": req.listing_id,
        "quantity": qty,
        "commitment": commitment_hex,
        "leaf_index": int(leaf_index),
        "note_hex": note_hex,
        "nonce_hex": nonce_hex,
        "created_at": now,
        "updated_at": now,
        "payment_mode": "note",
        "buyer_note_commitment": req.commitment,
        "buyer_note_nullifier": req.nullifier,
        # NO on-chain fields - pure note-based system
        "seller_can_claim": False,  # Will be True when buyer releases funds
        "seller_claimed": False,  # Will be True when seller generates payment note
        "encrypted_shipping": encrypted_shipping_blob if encrypted_shipping_blob else None,
    }
    st_esc["escrows"].append(escrow_record)
    _escrow_save(st_esc)
    _escrow_rebuild_root()

    try:
        ca.emit(
            "ListingSold",
            listing_id=req.listing_id,
            payment="note",
            price=str(total_price),
            unit_price=str(unit_price),
            quantity=qty,
            buyer=buyer_pub,
            seller=seller_pub,
            buyer_note_commitment=req.commitment,
            change_note=change_note_data,
            order_id=(shipping_commitment or {}).get("order_id") if shipping_commitment else None,
            escrow_id=escrow_id,
        )
    except Exception:
        pass

    return BuyRes(
        ok=True,
        listing_id=req.listing_id,
        payment="note",
        price=str(total_price),
        buyer_pub=buyer_pub,
        seller_pub=seller_pub,
        tx_signature="note_based_escrow",  # No on-chain transaction
        change_note=change_note_data,
        escrow_id=escrow_id,
    )

@app.post("/escrow/accept")
def escrow_accept(
    escrow_id: str = Body(..., embed=True),
    seller_keyfile: str = Body(..., embed=True),
):
    """Seller accepts an escrow order (note-based: NO on-chain transaction)."""
    st_esc = _escrow_state()
    escrow = _escrow_find(st_esc, escrow_id)
    if not escrow:
        raise HTTPException(404, "Escrow not found")

    # Check if this is a note-based escrow (no escrow_pda) or old on-chain escrow
    is_note_based = escrow.get("payment_mode") == "note" and not escrow.get("escrow_pda")

    if is_note_based:
        # NOTE-BASED ESCROW: No on-chain transaction, just update status
        print(f"[ESCROW_ACCEPT] Note-based escrow - NO on-chain transaction")

        # Verify seller
        seller_pub = ca.get_pubkey_from_keypair(seller_keyfile)
        if escrow.get("seller_pub") != seller_pub:
            raise HTTPException(403, "Only the seller can accept this escrow")

        if escrow.get("status") != "CREATED":
            raise HTTPException(400, f"Cannot accept escrow in status: {escrow.get('status')}")

        # Simply update status - no blockchain transaction needed
        escrow["status"] = "ACCEPTED"
        escrow["updated_at"] = _utcnow_iso()
        _escrow_save(st_esc)

        return {
            "ok": True,
            "escrow_id": escrow_id,
            "method": "note_based",
            "message": "Escrow accepted - no on-chain transaction needed"
        }

    # OLD ON-CHAIN ESCROW PATH (for backwards compatibility)
    escrow_pda = escrow.get("escrow_pda")
    if not escrow_pda:
        raise HTTPException(400, "Escrow PDA not found - not an on-chain escrow")

    try:
        # Try MPC version first (with encryption), fallback to regular accept if MPC not available
        import time
        computation_offset = int(time.time() * 1000)

        print(f"[DEBUG] Accepting escrow {escrow_id}")
        print(f"[DEBUG] Seller keyfile: {seller_keyfile}")
        print(f"[DEBUG] Escrow PDA: {escrow_pda}")

        try:
            # Try MPC version (requires Arcium network)
            print(f"[DEBUG] Attempting MPC accept with computation offset: {computation_offset}")
            result = ca.escrow_accept_order_mpc(seller_keyfile, escrow_pda, computation_offset)
            print(f"[DEBUG] MPC result: {result}")

            if not result.get("success"):
                raise Exception(f"MPC accept failed: {result.get('error')}")

            escrow["status"] = "ACCEPTED"
            escrow["updated_at"] = _utcnow_iso()
            escrow["accept_tx"] = result.get("acceptTx")
            escrow["stake_mpc_tx"] = result.get("stakeTx")
            _escrow_save(st_esc)

            return {
                "ok": True,
                "accept_tx": result.get("acceptTx"),
                "stake_mpc_tx": result.get("stakeTx"),
                "escrow_id": escrow_id,
                "method": "mpc"
            }

        except Exception as mpc_error:
            # MPC failed (likely Arcium not available on localnet), fallback to regular accept
            print(f"[WARN] MPC accept failed, falling back to regular accept: {str(mpc_error)}")

            result = ca.escrow_accept_order(seller_keyfile, escrow_pda)
            print(f"[DEBUG] Regular accept result: {result}")

            if not result.get("success"):
                raise Exception(f"Accept failed: {result.get('error')}")

            escrow["status"] = "ACCEPTED"
            escrow["updated_at"] = _utcnow_iso()
            escrow["accept_tx"] = result.get("tx")
            _escrow_save(st_esc)

            return {
                "ok": True,
                "accept_tx": result.get("tx"),
                "escrow_id": escrow_id,
                "method": "regular"
            }

    except Exception as e:
        import traceback
        print(f"[ERROR] Escrow accept failed: {str(e)}")
        print(f"[ERROR] Full traceback:")
        traceback.print_exc()
        raise HTTPException(500, f"Escrow accept failed: {str(e)}")

@app.post("/escrow/ship")
def escrow_ship(
    escrow_id: str = Body(..., embed=True),
    seller_keyfile: str = Body(..., embed=True),
    tracking_number: str = Body(..., embed=True),
):
    """Seller marks order as shipped (note-based: NO on-chain transaction)."""
    st_esc = _escrow_state()
    escrow = _escrow_find(st_esc, escrow_id)
    if not escrow:
        raise HTTPException(404, "Escrow not found")

    # Check if this is a note-based escrow
    is_note_based = escrow.get("payment_mode") == "note" and not escrow.get("escrow_pda")

    if is_note_based:
        # NOTE-BASED ESCROW: No on-chain transaction, just update status
        print(f"[ESCROW_SHIP] Note-based escrow - NO on-chain transaction")

        # Verify seller
        seller_pub = ca.get_pubkey_from_keypair(seller_keyfile)
        if escrow.get("seller_pub") != seller_pub:
            raise HTTPException(403, "Only the seller can mark as shipped")

        if escrow.get("status") != "ACCEPTED":
            raise HTTPException(400, f"Cannot ship escrow in status: {escrow.get('status')}")

        # Simply update status - no blockchain transaction needed
        escrow["status"] = "SHIPPED"
        escrow["updated_at"] = _utcnow_iso()
        escrow["tracking_number"] = tracking_number
        _escrow_save(st_esc)

        return {
            "ok": True,
            "escrow_id": escrow_id,
            "tracking_number": tracking_number,
            "method": "note_based"
        }

    # OLD ON-CHAIN ESCROW PATH
    escrow_pda = escrow.get("escrow_pda")
    if not escrow_pda:
        raise HTTPException(400, "Escrow PDA not found - not an on-chain escrow")

    try:
        result = ca.escrow_mark_shipped(seller_keyfile, escrow_pda, tracking_number)
        if not result.get("success"):
            raise Exception(f"Ship failed: {result.get('error')}")

        escrow["status"] = "SHIPPED"
        escrow["updated_at"] = _utcnow_iso()
        escrow["tracking_number"] = tracking_number
        escrow["ship_tx"] = result.get("tx")
        _escrow_save(st_esc)

        return {"ok": True, "tx": result.get("tx"), "escrow_id": escrow_id, "tracking_number": tracking_number}
    except Exception as e:
        raise HTTPException(500, f"Escrow ship failed: {str(e)}")

@app.post("/escrow/confirm")
def escrow_confirm(
    escrow_id: str = Body(..., embed=True),
    buyer_keyfile: str = Body(..., embed=True),
):
    """Buyer confirms delivery (note-based: NO on-chain transaction)."""
    st_esc = _escrow_state()
    escrow = _escrow_find(st_esc, escrow_id)
    if not escrow:
        raise HTTPException(404, "Escrow not found")

    # Check if this is a note-based escrow
    is_note_based = escrow.get("payment_mode") == "note" and not escrow.get("escrow_pda")

    if is_note_based:
        # NOTE-BASED ESCROW: No on-chain transaction, just update status
        print(f"[ESCROW_CONFIRM] Note-based escrow - NO on-chain transaction")

        # Verify buyer
        buyer_pub = ca.get_pubkey_from_keypair(buyer_keyfile)
        if escrow.get("buyer_pub") != buyer_pub:
            raise HTTPException(403, "Only the buyer can confirm delivery")

        if escrow.get("status") != "SHIPPED":
            raise HTTPException(400, f"Cannot confirm escrow in status: {escrow.get('status')}")

        # Update status and mark that seller can now claim payment note
        delivered_at = _utcnow_iso()
        escrow["status"] = "DELIVERED"
        escrow["updated_at"] = delivered_at
        escrow["delivered_at"] = delivered_at
        escrow["seller_can_claim"] = True  # Seller can now generate payment note
        _escrow_save(st_esc)

        return {
            "ok": True,
            "escrow_id": escrow_id,
            "method": "note_based",
            "message": "Delivery confirmed - seller can now claim payment"
        }

    # OLD ON-CHAIN ESCROW PATH
    escrow_pda = escrow.get("escrow_pda")
    if not escrow_pda:
        raise HTTPException(400, "Escrow PDA not found - not an on-chain escrow")

    try:
        result = ca.escrow_confirm_delivery(buyer_keyfile, escrow_pda)
        if not result.get("success"):
            raise Exception(f"Confirm failed: {result.get('error')}")

        delivered_at = _utcnow_iso()
        escrow["status"] = "DELIVERED"
        escrow["updated_at"] = delivered_at
        escrow["delivered_at"] = delivered_at
        escrow["confirm_tx"] = result.get("tx")
        _escrow_save(st_esc)

        return {"ok": True, "tx": result.get("tx"), "escrow_id": escrow_id}
    except Exception as e:
        raise HTTPException(500, f"Escrow confirm failed: {str(e)}")

@app.post("/escrow/buyer_release_early")
def escrow_buyer_release_early(
    escrow_id: str = Body(..., embed=True),
    buyer_keyfile: str = Body(..., embed=True),
):
    """
    Buyer releases funds to seller immediately (note-based: NO on-chain transaction).

    In note-based system:
    - Simply sets seller_can_claim = true
    - Seller then generates payment note CLIENT-SIDE (like making a deposit)
    - NO cSOL transfers, NO on-chain transactions
    """
    st_esc = _escrow_state()
    escrow = _escrow_find(st_esc, escrow_id)
    if not escrow:
        raise HTTPException(404, "Escrow not found")

    # Check if this is a note-based escrow
    is_note_based = escrow.get("payment_mode") == "note" and not escrow.get("escrow_pda")

    if is_note_based:
        # NOTE-BASED ESCROW: No payment transfer, just allow seller to claim
        print(f"[ESCROW_RELEASE] Note-based escrow - NO on-chain transaction")

        if escrow.get("status") != "DELIVERED":
            raise HTTPException(400, "Order must be delivered before early release")

        buyer_pub = ca.get_pubkey_from_keypair(buyer_keyfile) if os.path.exists(buyer_keyfile) else buyer_keyfile
        if escrow.get("buyer_pub") != buyer_pub:
            raise HTTPException(403, "Only the buyer can release funds early")

        # Mark that seller can claim payment note
        escrow["status"] = "COMPLETED"
        escrow["updated_at"] = _utcnow_iso()
        escrow["seller_can_claim"] = True  # Seller can now generate payment note
        escrow["early_release"] = True
        _escrow_save(st_esc)

        print(f"[ESCROW_RELEASE] Seller can now claim payment note for {escrow.get('amount_sol')} SOL")

        return {
            "ok": True,
            "escrow_id": escrow_id,
            "early_release": True,
            "method": "note_based",
            "message": "Funds released - seller can now claim payment note"
        }

    # OLD ON-CHAIN ESCROW PATH
    if escrow.get("status") != "DELIVERED":
        raise HTTPException(400, "Order must be delivered before early release")

    buyer_pub = ca.get_pubkey_from_keypair(buyer_keyfile) if os.path.exists(buyer_keyfile) else buyer_keyfile
    if escrow.get("buyer_pub") != buyer_pub:
        raise HTTPException(403, "Only the buyer can release funds early")

    escrow_pda = escrow.get("escrow_pda")
    seller_pub = escrow.get("seller_pub")
    amount_sol = escrow.get("amount_sol", "0")

    if not seller_pub:
        raise HTTPException(400, "Seller public key not found")

    try:
        amount_lamports = int(Decimal(amount_sol) * 1_000_000_000)

        wrapper_keyfile_abs = ca._wrapper_keypair_abs()

        from services.api.cli_adapter import escrow_pay_seller, MINT
        payment_tx = escrow_pay_seller(
            wrapper_keyfile=wrapper_keyfile_abs,
            seller_pubkey=seller_pub,
            amount_lamports=amount_lamports,
            mint=MINT,
        )

        print(f" Early release: Paid seller {seller_pub}: {amount_lamports} lamports (tx: {payment_tx})")

        escrow["status"] = "COMPLETED"
        escrow["updated_at"] = _utcnow_iso()
        escrow["finalize_tx"] = payment_tx
        escrow["early_release"] = True
        _escrow_save(st_esc)

        return {"ok": True, "tx": payment_tx, "escrow_id": escrow_id, "early_release": True}

    except Exception as e:
        print(f" Early release failed: {str(e)}")
        raise HTTPException(500, f"Early release failed: {str(e)}")

@app.post("/escrow/claim")
async def escrow_claim(
    escrow_id: str = Body(..., embed=True),
    seller_keyfile: str = Body(..., embed=True),
):
    """
    Seller claims payment note after escrow is completed.

    Note-based flow:
    1. Verify seller can claim (seller_can_claim = true)
    2. Generate payment note credentials (secret, nullifier, commitment)
    3. Return credentials to seller for CLIENT-SIDE encryption and storage
    4. Mark seller_claimed = true

    The seller will then encrypt and store this note, just like after a deposit.
    """
    st_esc = _escrow_state()
    escrow = _escrow_find(st_esc, escrow_id)
    if not escrow:
        raise HTTPException(404, "Escrow not found")

    # Check if this is a note-based escrow
    is_note_based = escrow.get("payment_mode") == "note" and not escrow.get("escrow_pda")

    if not is_note_based:
        raise HTTPException(400, "This endpoint is only for note-based escrows")

    print(f"[ESCROW_CLAIM] Note-based escrow claim")

    # Verify seller
    seller_pub = ca.get_pubkey_from_keypair(seller_keyfile)
    if escrow.get("seller_pub") != seller_pub:
        raise HTTPException(403, "Only the seller can claim payment")

    # Check if seller can claim
    if not escrow.get("seller_can_claim"):
        raise HTTPException(400, "Seller cannot claim yet - buyer must release funds first")

    # Check if already claimed
    if escrow.get("seller_claimed"):
        # Return existing payment note if available
        payment_note = escrow.get("payment_note")
        if payment_note:
            return {
                "ok": True,
                "already_claimed": True,
                "payment_note": payment_note,
                "escrow_id": escrow_id
            }
        raise HTTPException(400, "Payment already claimed")

    # Generate payment note credentials
    import secrets as sec
    import subprocess
    amount_sol = Decimal(escrow.get("amount_sol", "0"))

    seller_secret = sec.token_bytes(32)
    seller_nullifier = sec.token_bytes(32)

    from services.crypto_core.onchain_pool import h1, h2
    seller_commitment = h2(seller_secret, seller_nullifier)
    seller_nf_hash = h1(seller_nullifier)

    print(f"[ESCROW_CLAIM] Adding payment note to on-chain Merkle tree...")

    # Fetch current on-chain tree state
    deposit_history_script = Path(REPO_ROOT) / "contracts" / "incognito" / "scripts" / "get_deposit_history.ts"

    env = os.environ.copy()
    env["ANCHOR_PROVIDER_URL"] = "http://localhost:8899"
    env["ANCHOR_WALLET"] = str(Path(REPO_ROOT) / "keys" / "wrapper.json")

    try:
        result = subprocess.run(
            ["npx", "tsx", str(deposit_history_script)],
            cwd=deposit_history_script.parent.parent,
            env=env,
            capture_output=True,
            text=True,
            timeout=30
        )

        if result.returncode == 0:
            # Parse JSON from stdout (stderr contains logs)
            try:
                notes = json.loads(result.stdout)
                existing_leaves = []
                for note in notes:
                    commitment_bytes = bytes.fromhex(note["commitment"])
                    nf_hash_bytes = bytes.fromhex(note["nf_hash"])
                    leaf = h2(commitment_bytes, nf_hash_bytes)
                    existing_leaves.append(leaf.hex())

                print(f"[ESCROW_CLAIM] Fetched {len(existing_leaves)} existing leaves from on-chain")

                # Fallback to local file if on-chain history is empty (e.g., localnet restarted)
                if len(existing_leaves) == 0:
                    print(f"[ESCROW_CLAIM] ‚ö†Ô∏è  On-chain history empty, using local pool_merkle_state.json")
                    pool_merkle_path = Path(REPO_ROOT) / "pool_merkle_state.json"
                    if pool_merkle_path.exists():
                        with open(pool_merkle_path, 'r') as f:
                            local_state = json.load(f)
                        existing_leaves = local_state.get("leaves", [])
                        print(f"[ESCROW_CLAIM] Loaded {len(existing_leaves)} leaves from local file")

            except json.JSONDecodeError as json_err:
                print(f"[ESCROW_CLAIM] ‚ùå JSON parse error: {json_err}")
                print(f"[ESCROW_CLAIM] stdout: {result.stdout[:200]}")
                print(f"[ESCROW_CLAIM] stderr: {result.stderr[:200]}")
                raise HTTPException(500, f"Failed to parse on-chain state: {json_err}")
        else:
            print(f"[ESCROW_CLAIM] ‚ùå get_deposit_history failed:")
            print(f"[ESCROW_CLAIM]   stdout: {result.stdout}")
            print(f"[ESCROW_CLAIM]   stderr: {result.stderr}")
            raise HTTPException(500, f"Failed to fetch on-chain state: {result.stderr}")
    except subprocess.TimeoutExpired:
        raise HTTPException(500, "Timeout fetching on-chain state")
    except Exception as e:
        print(f"[ESCROW_CLAIM] ‚ùå Error fetching on-chain state: {e}")
        raise

    # Call add_claim_note.ts to add note to on-chain tree
    script_path = Path(REPO_ROOT) / "contracts" / "incognito" / "scripts" / "add_claim_note.ts"
    existing_leaves_csv = ",".join(existing_leaves) if existing_leaves else ""

    try:
        result = subprocess.run(
            ["npx", "tsx", str(script_path), seller_commitment.hex(), seller_nf_hash.hex(), existing_leaves_csv],
            cwd=script_path.parent.parent,
            env=env,
            capture_output=True,
            text=True,
            timeout=30
        )

        if result.returncode != 0:
            print(f"[ESCROW_CLAIM] On-chain call failed:")
            print(f"  STDOUT: {result.stdout}")
            print(f"  STDERR: {result.stderr}")
            raise RuntimeError(f"Failed to add claim note on-chain: {result.stderr}")

        output = json.loads(result.stdout)
        if not output.get("success"):
            raise RuntimeError(f"add_claim_note failed: {output.get('error', 'Unknown error')}")

        leaf_index = output["index"]
        tx_signature = output["tx"]

        print(f"[ESCROW_CLAIM] ‚úÖ Added to on-chain tree at index {leaf_index}")
        print(f"[ESCROW_CLAIM]   TX: {tx_signature}")

    except Exception as e:
        raise HTTPException(500, f"Failed to add payment note to on-chain tree: {str(e)}")

    # Update local pool_merkle_state.json to stay in sync with on-chain state
    print(f"[ESCROW_CLAIM] Updating local pool_merkle_state.json...")
    pool_merkle_path = Path(REPO_ROOT) / "pool_merkle_state.json"

    from services.crypto_core.onchain_pool import MerkleTree as PoolMerkleTree

    # Rebuild local tree from on-chain state (using existing_leaves fetched earlier)
    tree = PoolMerkleTree(depth=MERKLE_TREE_DEPTH)

    # Add all existing leaves from on-chain
    for leaf_hex in existing_leaves:
        tree.insert(bytes.fromhex(leaf_hex))

    print(f"[ESCROW_CLAIM] Loaded {len(existing_leaves)} existing leaves from on-chain")

    # Add the new payment note leaf
    payment_leaf = h2(seller_commitment, seller_nf_hash)
    tree.insert(payment_leaf)

    # Verify the leaf_index matches what we expect
    actual_leaf_index = len(tree.leaves) - 1
    if actual_leaf_index != leaf_index:
        print(f"[ESCROW_CLAIM] ‚ö†Ô∏è  WARNING: Expected leaf_index {leaf_index} but local tree has {actual_leaf_index}")
        print(f"[ESCROW_CLAIM] This might indicate a sync issue. Using on-chain index {leaf_index}")

    # Save updated tree
    with open(pool_merkle_path, 'w') as f:
        json.dump({
            "depth": tree.depth,
            "leaves": [leaf.hex() for leaf in tree.leaves],
            "leaf_count": len(tree.leaves)
        }, f, indent=2)

    print(f"[ESCROW_CLAIM] ‚úÖ Local tree updated, now has {len(tree.leaves)} leaves")

    # Create payment note data
    payment_note = {
        "secret": seller_secret.hex(),
        "nullifier": seller_nullifier.hex(),
        "commitment": seller_commitment.hex(),
        "amount_sol": float(amount_sol),
        "leaf_index": leaf_index,
        "tx_signature": tx_signature,
        "escrow_id": escrow_id,
        "generated_at": _utcnow_iso()
    }

    # Store payment note in DATABASE with client-side encryption
    from services.crypto_core.client_encryption import encrypt_note_from_keypair_file

    payment_note_plaintext = {
        "secret": seller_secret.hex(),
        "nullifier": seller_nullifier.hex(),
        "commitment": seller_commitment.hex(),
        "leaf_index": leaf_index,
        "amount_sol": float(amount_sol),
    }

    encrypted_blob = encrypt_note_from_keypair_file(payment_note_plaintext, seller_keyfile)

    await _save_note_for_user_db(
        owner_pub=seller_pub,
        encrypted_blob=encrypted_blob,
        commitment=seller_commitment.hex(),
        tx_signature=tx_signature,
        spent=False
    )

    # Store payment note in escrow and mark as claimed
    escrow["payment_note"] = payment_note
    escrow["seller_claimed"] = True
    escrow["claimed_at"] = _utcnow_iso()
    _escrow_save(st_esc)

    print(f"[ESCROW_CLAIM] Generated payment note for {amount_sol} SOL")
    print(f"[ESCROW_CLAIM] Payment note encrypted and saved in DATABASE for seller")

    return {
        "ok": True,
        "payment_note": payment_note,
        "escrow_id": escrow_id,
        "message": "Payment note added to on-chain tree - please encrypt and store it"
    }

@app.post("/escrow/finalize")
def escrow_finalize(
    escrow_id: str = Body(..., embed=True),
):
    """Finalize order after 7-day dispute window. Releases funds to seller and platform."""
    st_esc = _escrow_state()
    escrow = _escrow_find(st_esc, escrow_id)
    if not escrow:
        raise HTTPException(404, "Escrow not found")

    escrow_pda = escrow.get("escrow_pda")
    if not escrow_pda:
        raise HTTPException(400, "Escrow PDA not found - not an on-chain escrow")

    if escrow.get("status") not in ["DELIVERED", "COMPLETED"]:
        raise HTTPException(400, "Order must be delivered before finalization")

    try:
        # Use MPC version for fund distribution calculation
        import time
        computation_offset = int(time.time() * 1000)
        result = ca.escrow_finalize_order_mpc(escrow_pda, computation_offset)
        if not result.get("success"):
            error_msg = result.get('error', 'Unknown error')
            if "DeadlineNotReached" in error_msg:
                delivered_at = escrow.get("delivered_at")
                if delivered_at:
                    from datetime import datetime, timedelta
                    try:
                        delivered_time = datetime.fromisoformat(delivered_at.replace('Z', '+00:00'))
                        finalize_time = delivered_time + timedelta(days=7)
                        now = datetime.now(delivered_time.tzinfo)

                        if now < finalize_time:
                            remaining = finalize_time - now
                            hours_remaining = int(remaining.total_seconds() / 3600)
                            days_remaining = hours_remaining // 24
                            hours_in_day = hours_remaining % 24

                            if days_remaining > 0:
                                time_str = f"{days_remaining} days and {hours_in_day} hours"
                            else:
                                time_str = f"{hours_in_day} hours"

                            raise HTTPException(
                                400,
                                f"7-day dispute window not expired. Please wait {time_str} before finalizing (available at {finalize_time.strftime('%Y-%m-%d %H:%M UTC')})"
                            )
                    except Exception as calc_error:
                        pass

                raise HTTPException(
                    400,
                    "7-day dispute window has not expired yet. Please wait before finalizing."
                )
            raise Exception(f"Finalize failed: {error_msg}")

        escrow["status"] = "COMPLETED"
        escrow["updated_at"] = _utcnow_iso()
        escrow["finalize_tx"] = result.get("finalizeTx")
        escrow["distribution_mpc_tx"] = result.get("distributionTx")  # Store MPC computation TX
        _escrow_save(st_esc)

        return {
            "ok": True,
            "finalize_tx": result.get("finalizeTx"),
            "distribution_mpc_tx": result.get("distributionTx"),
            "escrow_id": escrow_id
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(500, f"Escrow finalize failed: {str(e)}")

@app.post("/shipping/put")
def put_encrypted_shipping(
    order_id: str = Body(..., embed=True),
    listing_id: str = Body(..., embed=True),
    buyer_pub: str = Body(..., embed=True),
    seller_pub: str = Body(..., embed=True),
    encrypted_shipping: Dict[str, Any] = Body(..., embed=True),
):
    if not isinstance(encrypted_shipping, dict):
        raise HTTPException(status_code=400, detail="encrypted_shipping must be an object")
    proof = _shipping_append_event(order_id, listing_id, buyer_pub, seller_pub, encrypted_shipping)
    return {
        "ok": True,
        "order_id": proof["order_id"],
        "leaf": proof["leaf"],
        "root": proof["root"],
        "index": proof["index"],
        "proof": proof["proof"],
    }

@app.get("/shipping/{order_id}")
def get_encrypted_shipping(order_id: str):
    res = _shipping_find_by_order(order_id)
    if not res:
        raise HTTPException(status_code=404, detail="Order not found")
    return res

def _ipfs_add_bytes(data: bytes, suffix: str = ".bin") -> str:
    """
    Upload bytes to IPFS. Returns ipfs:// URI on success, or None on failure.
    Includes 5-second timeout to prevent hanging.
    """
    with tempfile.NamedTemporaryFile("wb", delete=False, suffix=suffix) as f:
        f.write(data)
        tmp = f.name
    try:
        result = subprocess.run(
            ["ipfs", "add", "-Q", tmp],
            capture_output=True,
            text=True,
            check=False,
            timeout=5
        )
        if result.returncode == 0:
            cid = result.stdout.strip()
            if cid:
                return f"ipfs://{cid}"
        return None
    except subprocess.TimeoutExpired:
        print(f"IPFS upload timed out after 5 seconds")
        return None
    except FileNotFoundError:
        print(f"IPFS daemon not running or 'ipfs' command not found")
        return None
    except Exception as e:
        print(f"IPFS upload failed: {e}")
        return None
    finally:
        try:
            os.remove(tmp)
        except Exception:
            pass

def _as_http_image(uri: str) -> str:
    """Return a browser-viewable URL from ipfs:// or http(s):// using the configured gateway."""
    s = str(uri or "").strip()
    if not s:
        return s
    if s.startswith("ipfs://"):
        tail = s.split("://", 1)[1].lstrip("/")
        if tail.startswith("ipfs/"):
            tail = tail[5:]
        return f"{IPFS_GATEWAY.rstrip('/')}/{tail}"
    if s.startswith("/ipfs/"):
        return f"{IPFS_GATEWAY.rstrip('/')}/{s.split('/ipfs/', 1)[1]}"
    return s

def _normalize_listing(rec: dict) -> dict:
    if not isinstance(rec, dict):
        return {}
    imgs = rec.get("images") or rec.get("image_uris") or rec.get("imageUris") or []
    if isinstance(imgs, str):
        imgs = [x.strip() for x in imgs.split(",") if x.strip()]
    imgs_http = [_as_http_image(u) for u in imgs]
    return {
        "id": rec.get("id") or rec.get("listing_id") or rec.get("slug") or rec.get("pk"),
        "title": rec.get("title") or rec.get("name") or f"Listing {rec.get('id')}",
        "description": rec.get("description"),
        "unit_price_sol": str(rec.get("unit_price_sol") or rec.get("price_sol") or rec.get("price") or "0"),
        "quantity": int(rec.get("quantity", 0)),
        "seller_pub": rec.get("seller_pub") or rec.get("owner_pub") or rec.get("seller") or "",
        "active": bool(rec.get("active", True)) and int(rec.get("quantity", 0)) > 0,
        "images": imgs_http,
    }

@app.get("/listings", response_model=ListingsPayload)
def list_listings(seller_pub: Optional[str] = None, mine: bool = False):
    try:
        items = ca.listings_by_owner(seller_pub) if (seller_pub and mine) else ca.listings_active()
    except Exception:
        items = []
    norm = [_normalize_listing(x) for x in items]
    norm = [x for x in norm if x.get("active", True) and int(x.get("quantity", 0)) > 0]
    return {"items": norm}

@app.get("/listings/{listing_id}", response_model=Listing)
def get_listing(listing_id: str):
    rec = ca.listing_get(listing_id)
    if not rec:
        raise HTTPException(status_code=404, detail="Listing not found")
    return _normalize_listing(rec)

@app.post("/listings", response_model=ListingCreateRes)
async def create_listing(
    seller_keyfile: str = Form(...),
    title: str = Form(...),
    description: Optional[str] = Form(None),
    unit_price_sol: str = Form(...),
    quantity: int = Form(1),
    images: Optional[List[UploadFile]] = File(None),
    image_uris: Optional[str] = Form(None),
):
    seller_pub = ca.get_pubkey_from_keypair(seller_keyfile)
    uris: list[str] = []
    for f in images or []:
        try:
            data = await f.read()
            name = (f.filename or "").lower()
            suf = ".png" if name.endswith(".png") else ".jpg" if name.endswith(".jpg") or name.endswith(".jpeg") else ".bin"
            uri = _ipfs_add_bytes(data, suffix=suf)
            if uri:
                uris.append(uri)
        except Exception:
            continue
    if image_uris:
        try:
            extra = json.loads(image_uris)
            if isinstance(extra, list):
                uris.extend([str(u) for u in extra])
        except Exception:
            pass
    try:
        created = ca.listing_create(
            owner_pubkey=seller_pub,
            title=title,
            description=description,
            unit_price_sol=str(unit_price_sol),
            quantity=int(quantity),
            image_uris=uris,
        )
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Create failed: {e}")
    return {"ok": True, "listing": _normalize_listing(created)}

@app.patch("/listings/{listing_id}", response_model=ListingUpdateRes)
async def update_listing(
    listing_id: str,
    seller_keyfile: str = Form(...),
    title: Optional[str] = Form(None),
    description: Optional[str] = Form(None),
    unit_price_sol: Optional[str] = Form(None),
    quantity_new: Optional[int] = Form(None),
    quantity_delta: Optional[int] = Form(None),
    images: Optional[List[UploadFile]] = File(None),
    image_uris: Optional[str] = Form(None),
):
    seller_pub = ca.get_pubkey_from_keypair(seller_keyfile)
    rec = ca.listing_get(listing_id)
    if not rec:
        raise HTTPException(status_code=404, detail="Listing not found")
    if title is not None or description is not None:
        try:
            rec = ca.listing_update_meta(seller_pub, listing_id, title=title, description=description)
        except Exception:
            pass
    if unit_price_sol is not None:
        try:
            rec = ca.listing_update_price(seller_pub, listing_id, unit_price_sol)
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"Update price failed: {e}")
    if quantity_new is not None or quantity_delta is not None:
        try:
            rec = ca.listing_update_quantity(
                seller_pub, listing_id, quantity_new=quantity_new, quantity_delta=quantity_delta
            )
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"Update quantity failed: {e}")
    new_uris: list[str] = []
    for f in images or []:
        try:
            data = await f.read()
            name = (f.filename or "").lower()
            suf = ".png" if name.endswith(".png") else ".jpg" if name.endswith(".jpg") or name.endswith(".jpeg") else ".bin"
            uri = _ipfs_add_bytes(data, suffix=suf)
            if uri:
                new_uris.append(uri)
        except Exception:
            continue
    if image_uris:
        try:
            extra = json.loads(image_uris)
            if isinstance(extra, list):
                new_uris.extend([str(u) for u in extra])
        except Exception:
            pass
    if new_uris:
        try:
            rec = ca.listing_replace_images(seller_pub, listing_id, new_uris)
        except Exception:
            pass
    norm = _normalize_listing(rec)
    return {"ok": True, "listing": norm}

@app.delete("/listings/{listing_id}", response_model=ListingDeleteRes)
def delete_listing(listing_id: str, seller_keyfile: str):
    seller_pub = ca.get_pubkey_from_keypair(seller_keyfile)
    try:
        removed = ca.listing_delete(seller_pub, listing_id)
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Delete failed: {e}")
    return {"ok": True, "removed": int(removed)}


@app.get("/shipping/inbox/{seller_pub}")
def shipping_inbox(seller_pub: str):
    rows = _shipping_events_read_all()
    orders = []
    for r in rows:
        if r.get("type") != "shipping_blob":
            continue
        if r.get("seller_pub") != seller_pub:
            continue
        orders.append(
            {
                "order_id": r.get("order_id"),
                "ts": r.get("ts"),
                "listing_id": r.get("listing_id"),
                "buyer_pub": r.get("buyer_pub"),
                "payment": r.get("payment"),
                "unit_price": r.get("unit_price"),
                "quantity": r.get("quantity"),
                "total_price": r.get("total_price"),
            }
        )
    orders.sort(key=lambda x: x.get("ts") or "", reverse=True)
    return {"orders": orders}


def _profiles__ensure_files():
    if not os.path.exists(PROFILES_EVENTS):
        try:
            pathlib.Path(PROFILES_EVENTS).write_text("")
        except Exception:
            pass
    if not os.path.exists(PROFILES_MERKLE):
        try:
            pathlib.Path(PROFILES_MERKLE).write_text(
                json.dumps({"leaves": [], "root": None, "version": 1})
            )
        except Exception:
            pass

def _profiles_events_append(row: dict) -> None:
    try:
        with open(PROFILES_EVENTS, "a", encoding="utf-8") as f:
            f.write(json.dumps(row, separators=(",", ":")) + "\n")
    except Exception:
        pass

def _profiles_events_read_all() -> list[dict]:
    out = []
    try:
        with open(PROFILES_EVENTS, "r", encoding="utf-8") as f:
            for line in f:
                if not line.strip():
                    continue
                try:
                    out.append(json.loads(line))
                except Exception:
                    continue
    except FileNotFoundError:
        pass
    return out

def _profiles_load_state() -> Dict[str, Any]:
    _profiles__ensure_files()
    try:
        return json.loads(pathlib.Path(PROFILES_MERKLE).read_text())
    except Exception:
        return {"leaves": [], "root": None, "version": 1}

def _profiles_save_state(st: Dict[str, Any]) -> None:
    try:
        pathlib.Path(PROFILES_MERKLE).write_text(json.dumps(st))
    except Exception:
        pass

def _profile_leaf_hex(blob: Dict[str, Any]) -> str:
    return ca.profile_hash_profile_leaf(blob)

def _profiles_build_tree(leaves_hex: List[str]) -> MerkleTree:
    mt = OldMerkleTree(leaves_hex if isinstance(leaves_hex, list) else [])
    if not getattr(mt, "layers", None) and getattr(mt, "leaf_bytes", None):
        mt.build_tree()
    return mt

def _profiles_find_latest_by_username(username: str) -> Optional[Dict[str, Any]]:
    """Derni√®re entr√©e pour ce username (comparaison insensible √† la casse/suffixes)."""
    uname_norm = _normalize_username(username)
    rows = _profiles_events_read_all()
    stt = _profiles_load_state()
    leaves = stt.get("leaves") or []
    pos = {h: i for i, h in enumerate(leaves)}
    latest = None
    for r in rows:
        if r.get("kind") != "ProfileRegistered":
            continue
        b = r.get("blob") or {}
        if _normalize_username(str(b.get("username", ""))) != uname_norm:
            continue
        leaf = r.get("leaf") or _profile_leaf_hex(b)
        if leaf in pos:
            latest = {**r, "index": pos[leaf], "leaf": leaf}
    return latest

def _profiles_register_blob(blob: Dict[str, Any]) -> Dict[str, Any]:
    """Append a profile leaf (idempotent for identical blob), update Merkle, return proof pack."""
    _profiles__ensure_files()
    leaf_hex = _profile_leaf_hex(blob)
    stt = _profiles_load_state()
    leaves = list(stt.get("leaves") or [])
    if leaf_hex not in leaves:
        leaves.append(leaf_hex)
    stt["leaves"] = leaves
    _profiles_save_state(stt)
    mt = _profiles_build_tree(leaves)
    root_hex = mt.root().hex()
    stt["root"] = root_hex
    _profiles_save_state(stt)
    idx = leaves.index(leaf_hex)
    proof = mt.get_proof(idx)
    return {"leaf": leaf_hex, "root": root_hex, "index": idx, "proof": proof}


@app.post("/profiles/reveal", response_model=ProfileRevealRes)
def profiles_reveal(req: ProfileRevealReq):
    blob = req.blob.dict()
    pubs_new = list(blob.get("pubs") or [])
    sig_hex = str(blob.get("sig") or "")
    if not pubs_new:
        raise HTTPException(status_code=400, detail="blob.pubs required")
    if not sig_hex:
        raise HTTPException(status_code=400, detail="blob.sig required")
    latest = _profiles_find_latest_by_username(blob.get("username", ""))
    msg = ca.profile_canonical_json_bytes(blob)
    if latest is None:
        if not ca.profile_verify_owner_sig(msg, sig_hex, pubs_new):
            raise HTTPException(status_code=400, detail="Invalid owner signature for new profile")
        blob["version"] = int(blob.get("version") or 1)
    else:
        old_blob = latest.get("blob") or {}
        old_pubs = list(old_blob.get("pubs") or [])
        if not old_pubs:
            raise HTTPException(status_code=500, detail="Corrupt prior profile (no pubs)")
        if not ca.profile_verify_owner_sig(msg, sig_hex, old_pubs):
            raise HTTPException(status_code=409, detail="Username already registered by another owner")
        old_ver = int(old_blob.get("version", 1))
        new_ver = int(blob.get("version") or (old_ver + 1))
        if new_ver < old_ver:
            raise HTTPException(status_code=400, detail="version must be >= current")
        blob["version"] = new_ver
    pack = _profiles_register_blob(blob)
    ev_row = {
        "kind": "ProfileRegistered",
        "ts": datetime.utcnow().isoformat() + "Z",
        "leaf": pack["leaf"],
        "index": pack["index"],
        "root": pack["root"],
        "blob": blob,
    }
    _profiles_events_append(ev_row)
    try:
        ca.emit("ProfileRegistered", **ev_row)
        ca.emit("ProfilesMerkleRootUpdated", root_hex=pack["root"])
    except Exception:
        pass
    return ProfileRevealRes(
        ok=True, leaf=pack["leaf"], index=pack["index"], root=pack["root"], blob=ProfileBlob(**blob)
    )

@app.post("/profiles/rotate", response_model=ProfileRevealRes)
def profiles_rotate(req: ProfileRotateReq):
    """Auth de rotation: v√©rification sur le payload EXACT fourni (casse incluse). Recherche insensible √† la casse."""
    username_orig = (req.username or "").strip()
    latest = _profiles_find_latest_by_username(username_orig)
    if not latest:
        raise HTTPException(status_code=404, detail="Existing profile not found; use /profiles/reveal first")
    old_blob = latest.get("blob") or {}
    old_pubs = list(old_blob.get("pubs") or [])
    if not old_pubs:
        raise HTTPException(status_code=400, detail="Existing profile has no pubs[]")
    payload = {"username": username_orig, "new_pubs": list(req.new_pubs or []), "meta": req.meta or None}
    if not payload["new_pubs"]:
        raise HTTPException(status_code=400, detail="new_pubs required")
    msg = ca.profile_canonical_json_bytes(payload)
    if not ca.profile_verify_owner_sig(msg, req.sig, old_pubs):
        raise HTTPException(status_code=400, detail="Rotation must be signed by an existing owner key")
    new_blob = {
        "username": username_orig,
        "pubs": payload["new_pubs"],
        "version": int(old_blob.get("version", 1)) + 1,
        "meta": payload["meta"],
        "sig": "",
    }
    to_sign = ca.profile_canonical_json_bytes(new_blob).hex()
    return ProfileRevealRes(
        ok=True,
        leaf="",
        index=-1,
        root=_profiles_load_state().get("root") or "",
        blob=ProfileBlob(**{**new_blob, "sig": to_sign}),
    )

@app.post("/profiles/mark_stealth_used", response_model=MarkStealthUsedRes)
def mark_stealth_used(req: MarkStealthUsedReq):
    row = {
        "kind": "StealthMarkedUsed",
        "stealth_pub": req.stealth_pub,
        "reason": req.reason or "",
        "ts": datetime.utcnow().isoformat() + "Z",
    }
    try:
        with open(USED_STEALTH_PATH, "a", encoding="utf-8") as f:
            f.write(json.dumps(row, separators=(",", ":")) + "\n")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to append to used_stealth.jsonl: {e}")
    try:
        ca.emit("StealthMarkedUsed", **row)
    except Exception:
        pass
    return MarkStealthUsedRes(ok=True, stealth_pub=req.stealth_pub)

def _normalize_username(alias: str) -> str:
    s = (alias or "").strip()
    if s.startswith("@"):
        s = s[1:]
    if s.endswith(".incognito"):
        s = s[: -len(".incognito")]
    return s.lower()

def _resolve_username_to_pub(username: str) -> str:
    row = _profiles_find_latest_by_username(username)
    if not row:
        u = _normalize_username(username)
        raise HTTPException(status_code=404, detail=f"Profile '{u}' not found")
    blob = row.get("blob") or {}
    pubs = list(blob.get("pubs") or [])
    if not pubs:
        raise HTTPException(status_code=400, detail=f"Profile has no pubs[]")
    return pubs[0]

def _profiles_find_latest_by_pub(pub: str) -> Optional[Dict[str, Any]]:
    """Return the latest ProfileRegistered row where blob.pubs includes pub and the leaf still exists in current leaves."""
    rows = _profiles_events_read_all()
    stt = _profiles_load_state()
    leaves = stt.get("leaves") or []
    pos = {h: i for i, h in enumerate(leaves)}
    latest = None
    for r in rows:
        if r.get("kind") != "ProfileRegistered":
            continue
        b = r.get("blob") or {}
        pubs = list(b.get("pubs") or [])
        if pub not in pubs:
            continue
        leaf = r.get("leaf") or _profile_leaf_hex(b)
        if leaf in pos:
            latest = {**r, "index": pos[leaf], "leaf": leaf}
    return latest


from .schemas_api import ProfileResolveByPubRes


@app.get("/profiles/resolve/{username}", response_model=ProfileResolveRes)
def profiles_resolve(username: str):
    """Toujours 200. ok=false si introuvable. Comparaison insensible √† la casse via _profiles_find_latest_by_username()."""
    row = _profiles_find_latest_by_username(username)
    if not row:
        return ProfileResolveRes(ok=False, username=username)
    stt = _profiles_load_state()
    leaves = stt.get("leaves") or []
    mt = _profiles_build_tree(leaves)
    root_hex = mt.root().hex()
    idx = int(row["index"])
    proof_raw = mt.get_proof(idx) or []
    proof_hex = [p.hex() if isinstance(p, (bytes, bytearray)) else str(p) for p in proof_raw]
    blob = row.get("blob") or {}
    return ProfileResolveRes(
        ok=True,
        username=blob.get("username", username),
        leaf=row["leaf"],
        blob=ProfileBlob(**blob),
        index=idx,
        proof=proof_hex,
        root=root_hex,
    )

@app.get("/profiles/resolve_pub/{pub}", response_model=ProfileResolveByPubRes)
def profiles_resolve_pub(pub: str):
    row = _profiles_find_latest_by_pub(pub)
    if not row:
        return ProfileResolveByPubRes(ok=False, pub=pub)
    stt = _profiles_load_state()
    leaves = stt.get("leaves") or []
    mt = _profiles_build_tree(leaves)
    root_hex = mt.root().hex()
    idx = int(row["index"])
    proof_raw = mt.get_proof(idx) or []
    proof_hex = [p.hex() if isinstance(p, (bytes, bytearray)) else str(p) for p in proof_raw]
    blob = row.get("blob") or {}
    return ProfileResolveByPubRes(
        ok=True, pub=pub, username=blob.get("username"), leaf=row["leaf"], index=idx, root=root_hex, proof=proof_hex
    )

def _utcnow_iso() -> str:
    from datetime import timezone

    return datetime.now(timezone.utc).isoformat()

def _json_load(path: str, default: dict) -> dict:
    try:
        if os.path.exists(path):
            return json.loads(pathlib.Path(path).read_text())
    except Exception:
        pass
    return default

def _json_save(path: str, obj: dict) -> None:
    tmp = path + ".tmp"
    try:
        pathlib.Path(tmp).write_text(json.dumps(obj, indent=2))
        os.replace(tmp, path)
    except Exception:
        pass

def _escrow_state() -> dict:
    return _json_load(ESCROW_STATE_PATH, {"escrows": [], "nullifiers": []})

def _escrow_save(st: dict) -> None:
    _json_save(ESCROW_STATE_PATH, st)

def _escrow_merkle() -> dict:
    return _json_load(ESCROW_MERKLE_PATH, {"leaves": [], "root": ""})

def _escrow_merkle_save(ms: dict) -> None:
    _json_save(ESCROW_MERKLE_PATH, ms)

def _escrow_rebuild_root() -> str:
    ms = _escrow_merkle()
    mt = OldMerkleTree(ms.get("leaves", []))
    if not getattr(mt, "layers", None) and getattr(mt, "leaf_bytes", None):
        mt.build_tree()
    root = mt.root().hex() if hasattr(mt.root(), "hex") else (mt.root() or "")
    ms["root"] = root
    _escrow_merkle_save(ms)
    return root

def _escrow_find(st: dict, escrow_id: str) -> Optional[dict]:
    for e in st.get("escrows", []):
        if e.get("id") == escrow_id:
            return e
    return None

def _escrow_append_leaf(commitment_hex: str) -> int:
    ms = _escrow_merkle()
    leaves = list(ms.get("leaves") or [])
    leaves.append(commitment_hex)
    ms["leaves"] = leaves
    _escrow_merkle_save(ms)
    return len(leaves) - 1

def _mk_escrow_commitment(amount_str: str, seller_pub: str):
    """Uses your existing commitment primitive from cli_adapter (ca.*)."""
    note = secrets.token_bytes(32)
    nonce = secrets.token_bytes(24)
    commitment = ca.make_commitment(note, amount_str, nonce, seller_pub)
    return note.hex(), nonce.hex(), commitment

def _escrow_transition(cur: str, action: str, actor_pub: str, buyer_pub: str, seller_pub: str) -> str:
    action = action.upper()
    if action == "RELEASE":
        if actor_pub != buyer_pub:
            raise HTTPException(403, "Only the buyer can RELEASE funds.")
        if cur not in ("PENDING", "REFUND_REQUESTED", "DISPUTED"):
            raise HTTPException(400, f"Cannot RELEASE from {cur}.")
        return "RELEASED"
    if action == "REFUND_REQUEST":
        if actor_pub != buyer_pub:
            raise HTTPException(403, "Only the buyer can request a refund.")
        if cur != "PENDING":
            raise HTTPException(400, f"Cannot REFUND_REQUEST from {cur}.")
        return "REFUND_REQUESTED"
    if action == "REFUND":
        if actor_pub != seller_pub:
            raise HTTPException(403, "Only the seller can REFUND.")
        if cur not in ("PENDING", "REFUND_REQUESTED", "DISPUTED"):
            raise HTTPException(400, f"Cannot REFUND from {cur}.")
        return "REFUNDED"
    if action == "DISPUTE":
        if actor_pub not in (buyer_pub, seller_pub):
            raise HTTPException(403, "Only buyer or seller can DISPUTE.")
        if cur not in ("PENDING", "REFUND_REQUESTED"):
            raise HTTPException(400, f"Cannot DISPUTE from {cur}.")
        return "DISPUTED"
    if action == "CANCEL":
        if actor_pub not in (buyer_pub, seller_pub):
            raise HTTPException(403, "Only buyer or seller can CANCEL.")
        if cur != "PENDING":
            raise HTTPException(400, f"Cannot CANCEL from {cur}.")
        return "CANCELLED"
    raise HTTPException(400, f"Unknown action {action}")


@app.get("/escrow/merkle/status", response_model=EscrowMerkleStatus)
def escrow_merkle_status():
    ms = _escrow_merkle()
    root = _escrow_rebuild_root()
    return EscrowMerkleStatus(escrow_leaves=len(ms.get("leaves", [])), escrow_root_hex=root)

@app.get("/escrow/list", response_model=EscrowListRes)
def escrow_list(
    party_pub: Optional[str] = None,
    role: Optional[str] = None,
    status: Optional[str] = None,
):
    st = _escrow_state()
    items = list(st.get("escrows", []))
    if party_pub and role in ("buyer", "seller"):
        key = "buyer_pub" if role == "buyer" else "seller_pub"
        items = [e for e in items if e.get(key) == party_pub]
    elif party_pub:
        items = [e for e in items if e.get("buyer_pub") == party_pub or e.get("seller_pub") == party_pub]
    if status:
        items = [e for e in items if e.get("status") == status]
    return EscrowListRes(items=[EscrowRecord(**e) for e in items])

@app.get("/escrow/_debug_state")
def escrow_debug_state():
    """Return raw escrow state for diagnostics."""
    return _escrow_state()

@app.get("/escrow/{escrow_id}")
def escrow_get(escrow_id: str):
    """Get escrow details."""
    st_esc = _escrow_state()
    escrow = _escrow_find(st_esc, escrow_id)
    if not escrow:
        raise HTTPException(404, "Escrow not found")
    return {"ok": True, "escrow": escrow}

@app.post("/escrow", response_model=EscrowOpenRes)
def escrow_open(req: EscrowOpenReq):
    amount_str = str(Decimal(str(req.amount_sol)).quantize(CSOL_DEC))
    note_hex, nonce_hex, commitment_hex = _mk_escrow_commitment(amount_str, req.seller_pub)
    leaf_index = _escrow_append_leaf(commitment_hex)
    st = _escrow_state()
    escrow_id = secrets.token_hex(16)
    now = _utcnow_iso()
    record = {
        "id": escrow_id,
        "buyer_pub": ca.get_pubkey_from_keypair(req.buyer_keyfile) if os.path.exists(req.buyer_keyfile) else req.buyer_keyfile,
        "seller_pub": req.seller_pub,
        "amount_sol": amount_str,
        "status": "PENDING",
        "details_ct": req.details_ct.dict() if req.details_ct else None,
        "listing_id": req.listing_id,
        "quantity": int(req.quantity) if req.quantity else None,
        "commitment": commitment_hex,
        "leaf_index": int(leaf_index),
        "note_hex": note_hex,
        "nonce_hex": nonce_hex,
        "created_at": now,
        "updated_at": now,
    }
    st["escrows"].append(record)
    _escrow_save(st)
    _escrow_rebuild_root()
    return EscrowOpenRes(escrow=EscrowRecord(**record))

@app.post("/escrow/{escrow_id}/action", response_model=EscrowActionRes)
def escrow_action(escrow_id: str, req: EscrowActionReq):
    st = _escrow_state()
    e = _escrow_find(st, escrow_id)
    if not e:
        raise HTTPException(404, "Escrow not found")
    actor_pub = (
        ca.get_pubkey_from_keypair(req.actor_keyfile)
        if os.path.exists(req.actor_keyfile)
        else req.actor_keyfile
    )
    new_status = _escrow_transition(e["status"], req.action, actor_pub, e["buyer_pub"], e["seller_pub"])

    buyer_pub = e["buyer_pub"]
    seller_pub = e["seller_pub"]
    amt = Decimal(str(e["amount_sol"])).quantize(CSOL_DEC)
    payment_mode = str(e.get("payment_mode") or "csol")

    if new_status == "RELEASED":
        if payment_mode == "csol":
            _csol_add(seller_pub, amt)
        else:
            _ensure_reserve_has(amt)
            csol_sig = ca.csol_transfer_from_reserve(seller_pub, str(amt))
            try:
                ca.emit("EscrowReleasedPayout", escrow_id=escrow_id, csol_sig=csol_sig, amount=str(amt))
            except Exception:
                pass
    elif new_status in ("REFUNDED", "CANCELLED"):
        if payment_mode == "csol":
            _csol_add(buyer_pub, amt)
        else:
            stw = ca.load_wrapper_state()
            note = secrets.token_bytes(32).hex()
            nonce = secrets.token_bytes(16).hex()
            ca.add_note(stw, buyer_pub, ca.fmt_amt(amt), note, nonce)
            ca.save_wrapper_state(stw)
            try:
                ca.emit("MerkleRootUpdated", root_hex=ca.build_merkle(stw).root().hex())
            except Exception:
                pass

    e["status"] = new_status
    e["updated_at"] = _utcnow_iso()
    if req.note_ct:
        e.setdefault("action_notes", []).append(req.note_ct.dict())
    if new_status in ("RELEASED", "REFUNDED", "CANCELLED"):
        try:
            nf = ca.make_nullifier(bytes.fromhex(e["note_hex"]))
            st.setdefault("nullifiers", []).append(nf)
        except Exception:
            pass
    _escrow_save(st)
    _escrow_rebuild_root()
    return EscrowActionRes(escrow=EscrowRecord(**e))

def _messages__ensure_files():
    if not os.path.exists(MESSAGES_EVENTS_PATH):
        try:
            pathlib.Path(MESSAGES_EVENTS_PATH).write_text("")
        except Exception:
            pass
    if not os.path.exists(MESSAGES_MERKLE_PATH):
        try:
            pathlib.Path(MESSAGES_MERKLE_PATH).write_text(
                json.dumps({"leaves": [], "root": None, "version": 1})
            )
        except Exception:
            pass

def _messages_events_append(row: dict) -> None:
    """Append a message event to the encrypted database"""
    try:
        json_str = json.dumps(row, separators=(",", ":"))
        encrypted_line = _encrypt_db_line(json_str)

        with open(MESSAGES_EVENTS_PATH, "a", encoding="utf-8") as f:
            f.write(encrypted_line + "\n")
    except Exception:
        pass

def _messages_events_read_all() -> list[dict]:
    """Read all message events from the encrypted database (with backward compatibility)"""
    out = []
    try:
        with open(MESSAGES_EVENTS_PATH, "r", encoding="utf-8") as f:
            for line in f:
                s = line.strip()
                if not s:
                    continue

                decrypted = _decrypt_db_line(s)
                if decrypted:
                    try:
                        out.append(json.loads(decrypted))
                        continue
                    except Exception:
                        pass

                try:
                    out.append(json.loads(s))
                except Exception:
                    continue
    except FileNotFoundError:
        pass
    return out

def _messages_load_state() -> Dict[str, Any]:
    _messages__ensure_files()
    try:
        return json.loads(pathlib.Path(MESSAGES_MERKLE_PATH).read_text())
    except Exception:
        return {"leaves": [], "root": None, "version": 1}

def _messages_save_state(sta: Dict[str, Any]) -> None:
    try:
        pathlib.Path(MESSAGES_MERKLE_PATH).write_text(json.dumps(sta))
    except Exception:
        pass

def _messages_leaf_hex(blob: Dict[str, Any]) -> str:
    h = hashlib.sha256()
    h.update(b"msg|")
    h.update(json.dumps(blob, sort_keys=True, separators=(",", ":")).encode("utf-8"))
    return h.hexdigest()

def _messages_build_tree(leaves_hex: List[str]) -> MerkleTree:
    mt = OldMerkleTree(leaves_hex if isinstance(leaves_hex, list) else [])
    if not getattr(mt, "layers", None) and getattr(mt, "leaf_bytes", None):
        mt.build_tree()
    return mt

def _messages_append_and_prove(row_blob: Dict[str, Any]) -> Dict[str, Any]:
    _messages__ensure_files()
    stt = _messages_load_state()
    leaves = list(stt.get("leaves") or [])
    leaf = _messages_leaf_hex(row_blob)
    leaves.append(leaf)
    stt["leaves"] = leaves
    mt = _messages_build_tree(leaves)
    root = mt.root().hex()
    stt["root"] = root
    _messages_save_state(stt)
    idx = len(leaves) - 1
    proof = mt.get_proof(idx)
    ev = {"ts": datetime.utcnow().isoformat() + "Z", "leaf": leaf, "blob": row_blob}
    _messages_events_append(ev)
    return {"leaf": leaf, "root": root, "index": idx, "proof": proof}

def _get_message_db_encryption_key() -> bytes:
    """
    Get or create a 32-byte encryption key for encrypting the messages database at rest.

    Priority order:
    1. MESSAGES_DB_KEY environment variable (hex string)
    2. Derive from INCOGNITO_AUTHORITY keypair if available
    3. Generate and persist a new key in .messages_db_key file

    Returns 32 bytes for use with SecretBox
    """
    env_key = os.getenv("MESSAGES_DB_KEY")
    if env_key:
        try:
            key_bytes = bytes.fromhex(env_key)
            if len(key_bytes) == 32:
                return key_bytes
        except Exception:
            pass

    authority_path = os.getenv("INCOGNITO_AUTHORITY")
    if authority_path and os.path.exists(authority_path):
        try:
            with open(authority_path, 'r') as f:
                kp_data = json.load(f)
            seed = bytes(kp_data[:32])
            key = hashlib.sha256(seed + b"|messages-db-encryption-v1").digest()
            return key
        except Exception:
            pass

    key_file = os.path.join(DATA_DIR, ".messages_db_key")
    if os.path.exists(key_file):
        try:
            with open(key_file, 'rb') as f:
                key = f.read()
            if len(key) == 32:
                return key
        except Exception:
            pass

    new_key = secrets.token_bytes(32)
    try:
        os.makedirs(DATA_DIR, exist_ok=True)
        with open(key_file, 'wb') as f:
            f.write(new_key)
        os.chmod(key_file, 0o600)
    except Exception:
        pass

    return new_key

def _encrypt_db_line(plaintext_json: str) -> str:
    """Encrypt a single line of the database (JSON string) for storage"""
    key = _get_message_db_encryption_key()
    box = SecretBox(key)
    nonce = nacl_utils.random(24)
    ct = box.encrypt(plaintext_json.encode('utf-8'), nonce)
    return base64.b64encode(ct).decode('ascii')

def _decrypt_db_line(encrypted_b64: str) -> Optional[str]:
    """Decrypt a single line of the database"""
    try:
        key = _get_message_db_encryption_key()
        box = SecretBox(key)
        ct = base64.b64decode(encrypted_b64)
        pt = box.decrypt(ct)
        return pt.decode('utf-8')
    except Exception:
        return None

def _verify_ed25519_signature(message: str, signature_b58: str, pubkey_b58: str) -> bool:
    """
    Verify an Ed25519 signature.

    Args:
        message: The message that was signed (UTF-8 string)
        signature_b58: Base58-encoded signature (64 bytes)
        pubkey_b58: Base58-encoded public key (32 bytes)

    Returns:
        True if signature is valid, False otherwise
    """
    try:
        import base58
        from nacl.signing import VerifyKey
        from nacl.exceptions import BadSignatureError

        msg_bytes = message.encode('utf-8')
        sig_bytes = base58.b58decode(signature_b58)
        pub_bytes = base58.b58decode(pubkey_b58)

        if len(sig_bytes) != 64:
            return False
        if len(pub_bytes) != 32:
            return False

        verify_key = VerifyKey(pub_bytes)
        verify_key.verify(msg_bytes, sig_bytes)
        return True
    except (BadSignatureError, Exception):
        return False

def _check_timestamp_freshness(timestamp: int, max_age_seconds: int = 60) -> bool:
    """Check if a timestamp is within acceptable range of current time"""
    import time
    now = int(time.time())
    age = abs(now - timestamp)
    return age <= max_age_seconds


def _hkdf_sha256(shared: bytes, info: Dict[str, Any]) -> bytes:
    info_bytes = json.dumps(info, sort_keys=True, separators=(",", ":")).encode()
    prk = hashlib.sha256(shared + b"|incognito-msg").digest()
    okm = hashlib.sha256(prk + info_bytes).digest()
    return okm

def _compute_message_hmac(shared: bytes, ciphertext_hex: str) -> str:
    """Compute HMAC-SHA256 of ciphertext using shared secret for message authentication"""
    import hmac
    ct_bytes = bytes.fromhex(ciphertext_hex)
    mac = hmac.new(shared, ct_bytes, hashlib.sha256).digest()
    return mac.hex()

def _verify_message_hmac(shared: bytes, ciphertext_hex: str, hmac_hex: str) -> bool:
    """Verify HMAC signature on message ciphertext"""
    import hmac
    expected = _compute_message_hmac(shared, ciphertext_hex)
    return hmac.compare_digest(expected, hmac_hex)

def _encrypt_with_shared(shared: bytes, plaintext: bytes) -> tuple[str, str]:
    key = _hkdf_sha256(shared, {"v": 1, "algo": "x25519+xsalsa20poly1305"})
    nonce = nacl_utils.random(24)
    ct = SecretBox(key).encrypt(plaintext, nonce)
    return nonce.hex(), ct[24:].hex()

def _decrypt_with_shared(shared: bytes, nonce_hex: str, ct_hex: str) -> bytes:
    key = _hkdf_sha256(shared, {"v": 1, "algo": "x25519+xsalsa20poly1305"})
    box = SecretBox(key)
    nonce = bytes.fromhex(nonce_hex)
    ct = bytes.fromhex(ct_hex)
    return box.decrypt(nonce + ct)


def _send_memo_transfer(sender_keyfile: str, to_pub: str, memo_text: str) -> Optional[str]:
    try:
        rc, out, err = ca._run_rc(
            [
                "solana",
                "transfer",
                to_pub,
                "0",
                "--allow-unfunded-recipient",
                "--from",
                sender_keyfile,
                "--with-memo",
                memo_text,
                "--url",
                os.getenv("SOLANA_RPC_URL", "http://127.0.0.1:8899"),
                "--fee-payer",
                sender_keyfile,
                "--no-wait",
            ]
        )
        if rc != 0:
            return None
        return (out or "").strip().splitlines()[-1].strip()
    except Exception:
        return None


from .schemas_api import (
    MessageRow,
    MessageSendReq,
    MessageSendRes,
    MessagesListRes,
    MessagesMerkleStatus,
    MessageInboxReq,
    MessageSentReq,
)

@app.get("/messages/merkle/status", response_model=MessagesMerkleStatus)
def messages_merkle_status():
    ms = _messages_load_state()
    mt = _messages_build_tree(ms.get("leaves", []))
    root = mt.root().hex() if hasattr(mt.root(), "hex") else (mt.root() or "")
    return MessagesMerkleStatus(message_leaves=len(ms.get("leaves", [])), message_root_hex=root)

def _resolve_recipient_pub_or_username(
    recipient_pub: Optional[str], recipient_username: Optional[str]
) -> str:
    if recipient_pub:
        return recipient_pub
    return _resolve_username_to_pub(recipient_username or "")

@app.post("/messages/send", response_model=MessageSendRes)
def messages_send(req: MessageSendReq):
    # Validate sender keyfile path (prevents path traversal)
    try:
        sender_keyfile_validated = validate_keyfile_path(
            req.sender_keyfile,
            allowed_dirs=["keys", "test_keys", ".keys"],
            repo_root=REPO_ROOT
        )
    except ValidationError as e:
        raise HTTPException(
            status_code=400,
            detail=f"Invalid sender keyfile path: {str(e)}"
        )

    if not os.path.exists(sender_keyfile_validated):
        raise HTTPException(status_code=400, detail=f"sender_keyfile not found: {sender_keyfile_validated}")

    sender_pub_ed = ca.get_pubkey_from_keypair(sender_keyfile_validated)
    recip_pub_ed = _resolve_recipient_pub_or_username(req.recipient_pub, req.recipient_username)


    with open(sender_keyfile_validated, 'r') as f:
        sender_kp_data = json.load(f)
    sender_sk64 = bytes(sender_kp_data[:64])
    sender_ed_pub32 = bytes(sender_kp_data[32:64])

    recip_ed_pub32 = base58.b58decode(recip_pub_ed)

    from services.crypto_core.messages import shared_secret_from_ed25519
    shared = shared_secret_from_ed25519(sender_sk64, recip_ed_pub32)

    try:
        pt = base64.b64decode(req.plaintext_b64)
    except Exception:
        raise HTTPException(400, "Invalid base64")
    if len(pt) > 16 * 1024:
        raise HTTPException(413, "message too large")
    nonce_hex, ct_hex = _encrypt_with_shared(shared, pt)

    hmac_hex = _compute_message_hmac(shared, ct_hex)

    memo_sig = None
    if req.attach_onchain_memo:
        memo_payload = b"\x02" + sender_ed_pub32 + bytes.fromhex(nonce_hex) + bytes.fromhex(ct_hex)
        memo_b64 = base64.b64encode(memo_payload).decode()
        memo_sig = _send_memo_transfer(sender_keyfile_validated, recip_pub_ed, memo_b64)

    row_blob = {
        "from_pub": sender_pub_ed,
        "to_pub": recip_pub_ed,
        "algo": "x25519_static+xsalsa20poly1305",
        "nonce_hex": nonce_hex,
        "ciphertext_hex": ct_hex,
        "hmac_hex": hmac_hex,
        "memo_sig": memo_sig,
        "eph_pub_b58": None,
    }
    proof = _messages_append_and_prove(row_blob)
    try:
        ca.emit("MessageStored", **{**row_blob, **{k: proof[k] for k in ("leaf", "index", "root")}})
    except Exception:
        pass
    return MessageSendRes(
        ok=True,
        message=MessageRow(
            ts=datetime.utcnow().isoformat() + "Z",
            from_pub=sender_pub_ed,
            to_pub=recip_pub_ed,
            algo="x25519_static+xsalsa20poly1305",
            nonce_hex=nonce_hex,
            ciphertext_hex=ct_hex,
            hmac_hex=hmac_hex,
            memo_sig=memo_sig,
            eph_pub_b58=None,
            leaf=proof["leaf"],
            index=int(proof["index"]),
            root=proof["root"],
        ),
    )

@app.post("/messages/inbox", response_model=MessagesListRes)
def messages_inbox_authenticated(req: MessageInboxReq):
    """
    Get inbox messages (AUTHENTICATED).
    Requires signature proving ownership of owner_pub keypair.
    """
    if not _check_timestamp_freshness(req.timestamp, max_age_seconds=60):
        raise HTTPException(status_code=401, detail="Request timestamp expired (must be within 60s of server time)")

    message = f"inbox:{req.owner_pub}:{req.timestamp}"
    if not _verify_ed25519_signature(message, req.signature, req.owner_pub):
        raise HTTPException(status_code=403, detail="Invalid signature - authentication failed")

    rows = _messages_events_read_all()
    items = []
    root = _messages_load_state().get("root") or ""
    for r in rows:
        b = r.get("blob") or {}
        if b.get("to_pub") != req.owner_pub:
            continue
        if req.peer_pub and b.get("from_pub") != req.peer_pub:
            continue
        items.append(
            MessageRow(
                ts=r.get("ts"),
                from_pub=b.get("from_pub"),
                to_pub=b.get("to_pub"),
                algo=b.get("algo"),
                nonce_hex=b.get("nonce_hex"),
                ciphertext_hex=b.get("ciphertext_hex"),
                hmac_hex=b.get("hmac_hex"),
                memo_sig=b.get("memo_sig"),
                eph_pub_b58=b.get("eph_pub_b58"),
                leaf=r.get("leaf"),
                index=-1,
                root=root,
            )
        )
    items.sort(key=lambda x: x.ts, reverse=True)
    return MessagesListRes(items=items)

@app.get("/messages/inbox/{owner_pub}", response_model=MessagesListRes, deprecated=True)
def messages_inbox_legacy(owner_pub: str, peer_pub: Optional[str] = None):
    """
    Get inbox messages (DEPRECATED - use POST /messages/inbox with authentication).
    This endpoint is kept for backward compatibility but will be removed in a future version.
    """
    rows = _messages_events_read_all()
    items = []
    root = _messages_load_state().get("root") or ""
    for r in rows:
        b = r.get("blob") or {}
        if b.get("to_pub") != owner_pub:
            continue
        if peer_pub and b.get("from_pub") != peer_pub:
            continue
        items.append(
            MessageRow(
                ts=r.get("ts"),
                from_pub=b.get("from_pub"),
                to_pub=b.get("to_pub"),
                algo=b.get("algo"),
                nonce_hex=b.get("nonce_hex"),
                ciphertext_hex=b.get("ciphertext_hex"),
                hmac_hex=b.get("hmac_hex"),
                memo_sig=b.get("memo_sig"),
                eph_pub_b58=b.get("eph_pub_b58"),
                leaf=r.get("leaf"),
                index=-1,
                root=root,
            )
        )
    items.sort(key=lambda x: x.ts, reverse=True)
    return MessagesListRes(items=items)

@app.post("/messages/sent", response_model=MessagesListRes)
def messages_sent_authenticated(req: MessageSentReq):
    """
    Get sent messages (AUTHENTICATED).
    Requires signature proving ownership of owner_pub keypair.
    """
    if not _check_timestamp_freshness(req.timestamp, max_age_seconds=60):
        raise HTTPException(status_code=401, detail="Request timestamp expired (must be within 60s of server time)")

    message = f"sent:{req.owner_pub}:{req.timestamp}"
    if not _verify_ed25519_signature(message, req.signature, req.owner_pub):
        raise HTTPException(status_code=403, detail="Invalid signature - authentication failed")

    rows = _messages_events_read_all()
    items = []
    root = _messages_load_state().get("root") or ""
    for r in rows:
        b = r.get("blob") or {}
        if b.get("from_pub") != req.owner_pub:
            continue
        if req.peer_pub and b.get("to_pub") != req.peer_pub:
            continue
        items.append(
            MessageRow(
                ts=r.get("ts"),
                from_pub=b.get("from_pub"),
                to_pub=b.get("to_pub"),
                algo=b.get("algo"),
                nonce_hex=b.get("nonce_hex"),
                ciphertext_hex=b.get("ciphertext_hex"),
                hmac_hex=b.get("hmac_hex"),
                memo_sig=b.get("memo_sig"),
                eph_pub_b58=b.get("eph_pub_b58"),
                leaf=r.get("leaf"),
                index=-1,
                root=root,
            )
        )
    items.sort(key=lambda x: x.ts, reverse=True)
    return MessagesListRes(items=items)

@app.get("/messages/sent/{owner_pub}", response_model=MessagesListRes, deprecated=True)
def messages_sent_legacy(owner_pub: str, peer_pub: Optional[str] = None):
    """
    Get sent messages (DEPRECATED - use POST /messages/sent with authentication).
    This endpoint is kept for backward compatibility but will be removed in a future version.
    """
    rows = _messages_events_read_all()
    items = []
    root = _messages_load_state().get("root") or ""
    for r in rows:
        b = r.get("blob") or {}
        if b.get("from_pub") != owner_pub:
            continue
        if peer_pub and b.get("to_pub") != peer_pub:
            continue
        items.append(
            MessageRow(
                ts=r.get("ts"),
                from_pub=b.get("from_pub"),
                to_pub=b.get("to_pub"),
                algo=b.get("algo"),
                nonce_hex=b.get("nonce_hex"),
                ciphertext_hex=b.get("ciphertext_hex"),
                hmac_hex=b.get("hmac_hex"),
                memo_sig=b.get("memo_sig"),
                eph_pub_b58=b.get("eph_pub_b58"),
                leaf=r.get("leaf"),
                index=-1,
                root=root,
            )
        )
    items.sort(key=lambda x: x.ts, reverse=True)
    return MessagesListRes(items=items)



@app.get("/escrow/status")
def get_escrow_status():
    """Check if escrow platform is initialized and ready"""
    try:
        ca._ensure_escrow_platform_initialized()
        return {
            "status": "ready",
            "initialized": True,
            "program_id": ca.ESCROW_PROGRAM_ID,
        }
    except Exception as e:
        return {
            "status": "error",
            "initialized": False,
            "error": str(e),
            "program_id": ca.ESCROW_PROGRAM_ID,
        }

@app.get("/keypairs")
def get_keypairs():
    """Load and return public keys and secret keys for userA, userB, userC"""
    keys_dir = Path(__file__).parent.parent.parent / "keys"
    result = {}

    for user in ["userA", "userB", "userC"]:
        key_file = str(keys_dir / f"{user}.json")
        if os.path.exists(key_file):
            pub = get_pubkey_from_keypair(key_file)
            if pub:
                with open(key_file, "r") as f:
                    secret_key = json.load(f)
                result[user] = {
                    "publicKey": pub,
                    "secretKey": secret_key
                }

    return result

@app.get("/list-keypairs")
def list_keypairs():
    """List all available keypair files in the keys directory"""
    keys_dir = Path(__file__).parent.parent.parent / "keys"
    keypairs = []

    if not keys_dir.exists():
        return {"keypairs": []}

    for key_file in keys_dir.glob("*.json"):
        pub = get_pubkey_from_keypair(str(key_file))
        if pub:
            keypairs.append({
                "filename": key_file.name,
                "public_key": pub
            })

    return {"keypairs": keypairs}
